#!/bin/bash

# å¤§æ•°æ®é›†GPU Pipelineéƒ¨ç½²è„šæœ¬
# æ”¯æŒä¸‹è½½å’Œå¤„ç†å¤§å‹å•ç»†èƒRNAæµ‹åºæ•°æ®é›†

set -e

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

log_header() {
    echo ""
    echo "=================================================================="
    echo "   $1"
    echo "=================================================================="
    echo ""
}

# æ£€æŸ¥å‰ç½®æ¡ä»¶
check_prerequisites() {
    log_header "æ£€æŸ¥éƒ¨ç½²å‰ç½®æ¡ä»¶"
    
    # æ£€æŸ¥kubectl
    if ! command -v kubectl &> /dev/null; then
        log_error "kubectl æœªå®‰è£…æˆ–ä¸åœ¨PATHä¸­"
        exit 1
    fi
    log_success "kubectl å¯ç”¨"
    
    # æ£€æŸ¥é›†ç¾¤è¿æ¥
    if ! kubectl cluster-info &> /dev/null; then
        log_error "æ— æ³•è¿æ¥åˆ°Kubernetesé›†ç¾¤"
        exit 1
    fi
    log_success "Kubernetesé›†ç¾¤è¿æ¥æ­£å¸¸"
    
    # æ£€æŸ¥Tektonå‘½åç©ºé—´
    if ! kubectl get namespace tekton-pipelines &> /dev/null; then
        log_error "tekton-pipelineså‘½åç©ºé—´ä¸å­˜åœ¨"
        exit 1
    fi
    log_success "Tektonå‘½åç©ºé—´å­˜åœ¨"
    
    # æ£€æŸ¥GPUèŠ‚ç‚¹
    GPU_NODES=$(kubectl get nodes -l accelerator=nvidia-tesla-gpu --no-headers | wc -l)
    if [ "$GPU_NODES" -eq 0 ]; then
        log_warning "æœªæ‰¾åˆ°GPUèŠ‚ç‚¹ (æ ‡ç­¾: accelerator=nvidia-tesla-gpu)"
        log_warning "Pipelineå¯èƒ½æ— æ³•æ­£ç¡®è°ƒåº¦åˆ°GPUèŠ‚ç‚¹"
    else
        log_success "æ‰¾åˆ° $GPU_NODES ä¸ªGPUèŠ‚ç‚¹"
    fi
}

# æ£€æŸ¥å­˜å‚¨éœ€æ±‚
check_storage_requirements() {
    log_header "æ£€æŸ¥å­˜å‚¨éœ€æ±‚"
    
    # è·å–èŠ‚ç‚¹å­˜å‚¨ä¿¡æ¯
    log_info "æ£€æŸ¥èŠ‚ç‚¹å­˜å‚¨å®¹é‡..."
    kubectl top nodes 2>/dev/null || log_warning "æ— æ³•è·å–èŠ‚ç‚¹èµ„æºä½¿ç”¨æƒ…å†µ"
    
    # æ£€æŸ¥StorageClass
    if kubectl get storageclass local-path &> /dev/null; then
        log_success "local-path StorageClass å¯ç”¨"
    else
        log_warning "local-path StorageClass ä¸å­˜åœ¨ï¼ŒPVCå¯èƒ½æ— æ³•åˆ›å»º"
    fi
    
    log_info "å¤§æ•°æ®é›†pipelineéœ€è¦ä»¥ä¸‹å­˜å‚¨:"
    echo "  - å¤§æ•°æ®é›†å­˜å‚¨: 200Gi (ç”¨äºå­˜å‚¨ä¸‹è½½çš„æ•°æ®é›†)"
    echo "  - æ•°æ®é›†ç¼“å­˜: 100Gi (ç”¨äºç¼“å­˜ï¼Œæé«˜é‡å¤ä½¿ç”¨æ•ˆç‡)"  
    echo "  - å¤„ç†å·¥ä½œåŒº: 150Gi (ç”¨äºnotebookæ‰§è¡Œå’Œç»“æœ)"
    echo "  - æ€»è®¡éœ€æ±‚: ~450Gi"
    echo ""
}

# éƒ¨ç½²å¤§æ•°æ®é›†å­˜å‚¨èµ„æº
deploy_large_dataset_storage() {
    log_header "éƒ¨ç½²å¤§æ•°æ®é›†å­˜å‚¨èµ„æº"
    
    log_info "åˆ›å»ºå¤§æ•°æ®é›†å­˜å‚¨PVC..."
    if kubectl apply -f examples/workspaces/large-dataset-workspaces.yaml; then
        log_success "å¤§æ•°æ®é›†å­˜å‚¨PVCåˆ›å»ºæˆåŠŸ"
    else
        log_error "å¤§æ•°æ®é›†å­˜å‚¨PVCåˆ›å»ºå¤±è´¥"
        exit 1
    fi
    
    # ç­‰å¾…PVCç»‘å®š
    log_info "ç­‰å¾…PVCç»‘å®š..."
    sleep 5
    
    # æ£€æŸ¥PVCçŠ¶æ€
    log_info "æ£€æŸ¥PVCçŠ¶æ€:"
    kubectl get pvc -n tekton-pipelines | grep -E "(large-dataset|dataset-cache|processing-workspace)" || true
    
    # éªŒè¯PVCç»‘å®šçŠ¶æ€
    PENDING_PVCS=$(kubectl get pvc -n tekton-pipelines | grep -E "(large-dataset|dataset-cache|processing-workspace)" | grep Pending | wc -l)
    if [ "$PENDING_PVCS" -gt 0 ]; then
        log_warning "$PENDING_PVCS ä¸ªPVCä»å¤„äºPendingçŠ¶æ€"
        log_warning "è¿™å¯èƒ½ä¼šå½±å“pipelineæ‰§è¡Œ"
    else
        log_success "æ‰€æœ‰å¤§æ•°æ®é›†å­˜å‚¨PVCå·²æˆåŠŸç»‘å®š"
    fi
}

# éƒ¨ç½²ä»»åŠ¡å®šä¹‰
deploy_tasks() {
    log_header "éƒ¨ç½²ä»»åŠ¡å®šä¹‰"
    
    # éƒ¨ç½²å¤§æ•°æ®é›†ä¸‹è½½ä»»åŠ¡
    log_info "éƒ¨ç½²å¤§æ•°æ®é›†ä¸‹è½½ä»»åŠ¡..."
    if kubectl apply -f examples/tasks/large-dataset-download-task.yaml; then
        log_success "å¤§æ•°æ®é›†ä¸‹è½½ä»»åŠ¡éƒ¨ç½²æˆåŠŸ"
    else
        log_error "å¤§æ•°æ®é›†ä¸‹è½½ä»»åŠ¡éƒ¨ç½²å¤±è´¥"
        exit 1
    fi
    
    # æ£€æŸ¥ç°æœ‰ä»»åŠ¡
    log_info "æ£€æŸ¥å¿…éœ€çš„ä»»åŠ¡æ˜¯å¦å­˜åœ¨:"
    REQUIRED_TASKS=("gpu-env-preparation-fixed" "gpu-papermill-execution" "jupyter-nbconvert" "pytest-execution")
    
    for task in "${REQUIRED_TASKS[@]}"; do
        if kubectl get task "$task" -n tekton-pipelines &> /dev/null; then
            log_success "ä»»åŠ¡ $task å­˜åœ¨"
        else
            log_error "å¿…éœ€çš„ä»»åŠ¡ $task ä¸å­˜åœ¨"
            exit 1
        fi
    done
}

# éªŒè¯éƒ¨ç½²
verify_deployment() {
    log_header "éªŒè¯éƒ¨ç½²"
    
    log_info "æ£€æŸ¥éƒ¨ç½²çš„èµ„æº:"
    
    # æ£€æŸ¥ä»»åŠ¡
    echo "ğŸ“‹ ä»»åŠ¡åˆ—è¡¨:"
    kubectl get tasks -n tekton-pipelines | grep -E "(large-dataset|gpu-)" || true
    
    echo ""
    echo "ğŸ’¾ å­˜å‚¨èµ„æº:"
    kubectl get pvc -n tekton-pipelines | grep -E "(large-dataset|dataset-cache|processing-workspace)" || true
    
    echo ""
    echo "ğŸ·ï¸  GPUèŠ‚ç‚¹ä¿¡æ¯:"
    kubectl get nodes -l accelerator=nvidia-tesla-gpu -o wide || log_warning "æœªæ‰¾åˆ°æ ‡è®°çš„GPUèŠ‚ç‚¹"
}

# æ˜¾ç¤ºä½¿ç”¨è¯´æ˜
show_usage_instructions() {
    log_header "ä½¿ç”¨è¯´æ˜"
    
    cat << 'EOF'
å¤§æ•°æ®é›†GPU Pipelineå·²éƒ¨ç½²å®Œæˆï¼

ğŸš€ æ‰§è¡Œå¤§æ•°æ®é›†pipeline:
```bash
# åº”ç”¨pipelineé…ç½®
kubectl apply -f examples/pipelines/gpu-original-notebook-with-download.yaml

# ç›‘æ§æ‰§è¡ŒçŠ¶æ€
kubectl get pipelinerun gpu-original-notebook-with-download -n tekton-pipelines -w

# æŸ¥çœ‹è¯¦ç»†çŠ¶æ€
kubectl describe pipelinerun gpu-original-notebook-with-download -n tekton-pipelines
```

ğŸ“Š è‡ªå®šä¹‰æ•°æ®é›†ä¸‹è½½:
```bash
# ä¿®æ”¹pipelineå‚æ•°ä»¥ä½¿ç”¨ä¸åŒçš„æ•°æ®é›†
# ç¼–è¾‘ examples/pipelines/gpu-original-notebook-with-download.yaml ä¸­çš„å‚æ•°:
#   - dataset-url: æ•°æ®é›†ä¸‹è½½URL
#   - dataset-filename: ä¿å­˜çš„æ–‡ä»¶å
#   - expected-dataset-size-mb: é¢„æœŸæ–‡ä»¶å¤§å°(MB)
#   - download-timeout-minutes: ä¸‹è½½è¶…æ—¶æ—¶é—´
#   - max-download-retries: æœ€å¤§é‡è¯•æ¬¡æ•°
```

ğŸ” ç›‘æ§å’Œè°ƒè¯•:
```bash
# æŸ¥çœ‹ä¸‹è½½ä»»åŠ¡æ—¥å¿—
kubectl logs -f -l tekton.dev/task=large-dataset-download -n tekton-pipelines

# æŸ¥çœ‹GPUæ‰§è¡Œä»»åŠ¡æ—¥å¿—  
kubectl logs -f -l tekton.dev/task=gpu-papermill-execution -n tekton-pipelines

# æ£€æŸ¥å­˜å‚¨ä½¿ç”¨æƒ…å†µ
kubectl exec -it <pod-name> -n tekton-pipelines -- df -h
```

ğŸ’¾ å­˜å‚¨ç®¡ç†:
```bash
# æ¸…ç†ç¼“å­˜æ•°æ®
kubectl exec -it <pod-name> -n tekton-pipelines -- rm -rf /workspace/datasets/cache/*

# æŸ¥çœ‹å­˜å‚¨ä½¿ç”¨æƒ…å†µ
kubectl get pvc -n tekton-pipelines
kubectl describe pvc large-dataset-storage -n tekton-pipelines
```

âš™ï¸ æ€§èƒ½ä¼˜åŒ–å»ºè®®:
- å¯¹äºè¶…å¤§æ•°æ®é›†(>10GB)ï¼Œè€ƒè™‘å¢åŠ å­˜å‚¨é…ç½®
- æ ¹æ®ç½‘ç»œç¯å¢ƒè°ƒæ•´ä¸‹è½½è¶…æ—¶æ—¶é—´
- å¯ç”¨ç¼“å­˜æœºåˆ¶é¿å…é‡å¤ä¸‹è½½
- ç›‘æ§GPUå†…å­˜ä½¿ç”¨ï¼Œå¿…è¦æ—¶è°ƒæ•´batch size

EOF
}

# ä¸»å‡½æ•°
main() {
    case "${1:-deploy}" in
        "deploy"|"")
            log_header "å¼€å§‹éƒ¨ç½²å¤§æ•°æ®é›†GPU Pipeline"
            check_prerequisites
            check_storage_requirements
            deploy_large_dataset_storage
            deploy_tasks
            verify_deployment
            show_usage_instructions
            log_success "å¤§æ•°æ®é›†GPU Pipelineéƒ¨ç½²å®Œæˆï¼"
            ;;
        "storage-only")
            check_prerequisites
            deploy_large_dataset_storage
            ;;
        "verify")
            verify_deployment
            ;;
        "clean")
            log_warning "æ¸…ç†å¤§æ•°æ®é›†ç›¸å…³èµ„æº..."
            kubectl delete -f examples/workspaces/large-dataset-workspaces.yaml --ignore-not-found=true
            kubectl delete task large-dataset-download -n tekton-pipelines --ignore-not-found=true
            log_success "æ¸…ç†å®Œæˆ"
            ;;
        *)
            echo "ç”¨æ³•: $0 [deploy|storage-only|verify|clean]"
            echo ""
            echo "é€‰é¡¹:"
            echo "  deploy       - å®Œæ•´éƒ¨ç½² (é»˜è®¤)"
            echo "  storage-only - ä»…éƒ¨ç½²å­˜å‚¨èµ„æº"
            echo "  verify       - éªŒè¯éƒ¨ç½²çŠ¶æ€"
            echo "  clean        - æ¸…ç†ç›¸å…³èµ„æº"
            ;;
    esac
}

# æ‰§è¡Œä¸»å‡½æ•°
main "$@" 
apiVersion: tekton.dev/v1
kind: PipelineRun
metadata:
  name: gpu-demo-pipeline
  namespace: tekton-pipelines
  labels:
    app: gpu-scientific-computing
    trigger: manual
    gpu-pipeline: "true"
    test-type: "demo-pipeline"
  annotations:
    tekton.dev/pipeline-type: "gpu-scientific-computing-demo"
    tekton.dev/test-notebook: "demo_notebook.ipynb"
    tekton.dev/execution-mode: "demo"
spec:
  pipelineSpec:
    description: |
      Demo GPU-accelerated scientific computing pipeline using verified working notebook.
      This proves the end-to-end functionality of the Tekton GPU pipeline infrastructure.
    
    params:
    - name: git-repo-url
      description: Git repository URL containing the notebook to execute
      type: string
      default: "https://github.com/johnnynv/Real-world_Tekton_Installation_Guide.git"
    - name: git-revision
      description: Git revision to checkout
      type: string
      default: "main"
    - name: output-notebook-name
      description: Name for the executed notebook output
      type: string
      default: "demo_executed_notebook.ipynb"
    - name: output-html-name
      description: Name for the HTML conversion output
      type: string
      default: "demo_executed_notebook.html"
    - name: container-image
      description: GPU-enabled container image for notebook execution
      type: string
      default: "nvcr.io/nvidia/rapidsai/notebooks:25.04-cuda12.8-py3.12"
    
    workspaces:
    - name: shared-artifacts-workspace
      description: Shared workspace for all tasks
    
    tasks:
    # Task 1: Environment preparation and code checkout
    - name: prepare-environment
      taskRef:
        name: gpu-env-preparation-fixed
      params:
      - name: git-repo-url
        value: $(params.git-repo-url)
      - name: git-revision
        value: $(params.git-revision)
      - name: verbose
        value: "true"
      workspaces:
      - name: shared-storage
        workspace: shared-artifacts-workspace
    
    # Task 2: Create working demo notebook
    - name: create-demo-notebook
      runAfter: ["prepare-environment"]
      workspaces:
      - name: shared-storage
        workspace: shared-artifacts-workspace
      taskSpec:
        workspaces:
        - name: shared-storage
        steps:
        - name: create-notebook
          image: alpine:latest
          script: |
            #!/bin/sh
            set -eu
            
            echo "📝 Creating demo notebook for pipeline verification..."
            cd $(workspaces.shared-storage.path)
            
            # Create a working demo notebook based on our successful test
            cat > notebooks/demo_notebook.ipynb << 'EOF'
            {
             "cells": [
              {
               "cell_type": "markdown",
               "metadata": {},
               "source": [
                "# GPU Scientific Computing Demo\n",
                "This notebook demonstrates successful GPU-accelerated scientific computing in Tekton pipeline."
               ]
              },
              {
               "cell_type": "code",
               "execution_count": null,
               "metadata": {},
               "outputs": [],
               "source": [
                "import scanpy as sc\n",
                "import cupy as cp\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings(\"ignore\")\n",
                "\n",
                "print('🚀 Starting GPU Scientific Computing Demo')\n",
                "print(f'CuPy version: {cp.__version__}')\n",
                "print(f'NumPy version: {np.__version__}')\n",
                "print(f'Pandas version: {pd.__version__}')"
               ]
              },
              {
               "cell_type": "code", 
               "execution_count": null,
               "metadata": {},
               "outputs": [],
               "source": [
                "# GPU Memory Management with RMM\n",
                "import rmm\n",
                "from rmm.allocators.cupy import rmm_cupy_allocator\n",
                "\n",
                "print(f'🔧 Initializing RMM (version: {rmm.__version__})...')\n",
                "\n",
                "try:\n",
                "    rmm.reinitialize(\n",
                "        managed_memory=False,\n",
                "        pool_allocator=False,\n",
                "        devices=0\n",
                "    )\n",
                "    cp.cuda.set_allocator(rmm_cupy_allocator)\n",
                "    print('✅ RMM initialization successful')\n",
                "except Exception as e:\n",
                "    print(f'❌ RMM initialization failed: {e}')\n",
                "    raise"
               ]
              },
              {
               "cell_type": "code",
               "execution_count": null,
               "metadata": {},
               "outputs": [],
               "source": [
                "# Demonstrate GPU-accelerated operations\n",
                "print('🧪 Running GPU-accelerated computations...')\n",
                "\n",
                "# Create large arrays for computation\n",
                "size = 1000000\n",
                "a_gpu = cp.random.random((size,), dtype=cp.float32)\n",
                "b_gpu = cp.random.random((size,), dtype=cp.float32)\n",
                "\n",
                "# GPU computation\n",
                "result_gpu = cp.sqrt(a_gpu**2 + b_gpu**2)\n",
                "mean_result = cp.mean(result_gpu)\n",
                "\n",
                "print(f'✅ GPU computation completed')\n",
                "print(f'Array size: {size:,} elements')\n",
                "print(f'Mean result: {float(mean_result):.6f}')\n",
                "print(f'GPU memory usage: {cp.get_default_memory_pool().used_bytes() / 1024**2:.1f} MB')"
               ]
              },
              {
               "cell_type": "code",
               "execution_count": null,
               "metadata": {},
               "outputs": [],
               "source": [
                "# Scientific computing simulation\n",
                "print('🔬 Simulating scientific data analysis...')\n",
                "\n",
                "# Create synthetic 'single-cell' data\n",
                "n_cells = 5000\n",
                "n_genes = 2000\n",
                "\n",
                "# Generate synthetic expression matrix on GPU\n",
                "expression_matrix = cp.random.negative_binomial(5, 0.3, (n_cells, n_genes)).astype(cp.float32)\n",
                "\n",
                "# Basic preprocessing operations\n",
                "print(f'📊 Processing {n_cells:,} cells × {n_genes:,} genes matrix')\n",
                "\n",
                "# Normalization\n",
                "library_sizes = cp.sum(expression_matrix, axis=1, keepdims=True)\n",
                "normalized_matrix = expression_matrix / library_sizes * 10000\n",
                "\n",
                "# Log transformation\n",
                "log_normalized = cp.log1p(normalized_matrix)\n",
                "\n",
                "# Basic statistics\n",
                "mean_expression = cp.mean(log_normalized, axis=0)\n",
                "std_expression = cp.std(log_normalized, axis=0)\n",
                "\n",
                "print(f'✅ Analysis completed')\n",
                "print(f'Mean expression range: {float(cp.min(mean_expression)):.3f} - {float(cp.max(mean_expression)):.3f}')\n",
                "print(f'Expression std range: {float(cp.min(std_expression)):.3f} - {float(cp.max(std_expression)):.3f}')"
               ]
              },
              {
               "cell_type": "code",
               "execution_count": null,
               "metadata": {},
               "outputs": [],
               "source": [
                "# Generate summary results\n",
                "import json\n",
                "from datetime import datetime\n",
                "\n",
                "results = {\n",
                "    'timestamp': datetime.now().isoformat(),\n",
                "    'pipeline_type': 'GPU Scientific Computing Demo',\n",
                "    'gpu_device_count': cp.cuda.runtime.getDeviceCount(),\n",
                "    'cupy_version': cp.__version__,\n",
                "    'rmm_version': rmm.__version__,\n",
                "    'analysis_results': {\n",
                "        'n_cells': int(n_cells),\n",
                "        'n_genes': int(n_genes),\n",
                "        'mean_expression_range': [float(cp.min(mean_expression)), float(cp.max(mean_expression))],\n",
                "        'std_expression_range': [float(cp.min(std_expression)), float(cp.max(std_expression))]\n",
                "    },\n",
                "    'status': 'SUCCESS'\n",
                "}\n",
                "\n",
                "print('📋 Final Results:')\n",
                "print(json.dumps(results, indent=2))\n",
                "\n",
                "# Save results\n",
                "with open('/workspace/shared/artifacts/demo_results.json', 'w') as f:\n",
                "    json.dump(results, f, indent=2)\n",
                "\n",
                "print('\\n🎉 GPU Scientific Computing Demo completed successfully!')\n",
                "print('✅ All GPU operations executed without errors')\n",
                "print('✅ Results saved to demo_results.json')"
               ]
              }
             ],
             "metadata": {
              "kernelspec": {
               "display_name": "Python 3",
               "language": "python", 
               "name": "python3"
              },
              "language_info": {
               "name": "python",
               "version": "3.12.9"
              }
             },
             "nbformat": 4,
             "nbformat_minor": 4
            }
            EOF
            
            echo "✅ Demo notebook created successfully"
            echo "📊 Notebook size: $(du -h notebooks/demo_notebook.ipynb | cut -f1)"
    
    # Task 3: GPU-accelerated notebook execution with demo notebook
    - name: execute-demo-notebook
      taskRef:
        name: gpu-papermill-execution
      runAfter: ["create-demo-notebook"]
      params:
      - name: notebook-path
        value: "notebooks/demo_notebook.ipynb"
      - name: output-notebook-name
        value: $(params.output-notebook-name)
      - name: container-image
        value: $(params.container-image)
      - name: gpu-count
        value: "1"
      - name: memory-limit
        value: "16Gi"
      - name: cpu-limit
        value: "4"
      workspaces:
      - name: shared-storage
        workspace: shared-artifacts-workspace
    
    # Task 4: Convert notebook to HTML
    - name: convert-to-html
      taskRef:
        name: jupyter-nbconvert
      runAfter: ["execute-demo-notebook"]
      params:
      - name: input-notebook-name
        value: $(params.output-notebook-name)
      - name: output-html-name
        value: $(params.output-html-name)
      - name: embed-images
        value: "true"
      workspaces:
      - name: shared-storage
        workspace: shared-artifacts-workspace
    
    # Task 5: Verify results
    - name: verify-results
      runAfter: ["convert-to-html"]
      workspaces:
      - name: shared-storage
        workspace: shared-artifacts-workspace
      taskSpec:
        workspaces:
        - name: shared-storage
        steps:
        - name: verify-step
          image: alpine:latest
          script: |
            #!/bin/sh
            set -eu
            
            echo "🔍 Verifying pipeline results..."
            cd $(workspaces.shared-storage.path)
            
            echo "📁 Checking generated files:"
            ls -la artifacts/
            
            # Check executed notebook
            if [ -f "artifacts/$(params.output-notebook-name)" ]; then
              echo "✅ Executed notebook: $(du -h artifacts/$(params.output-notebook-name) | cut -f1)"
            else
              echo "❌ Executed notebook missing"
              exit 1
            fi
            
            # Check HTML output
            if [ -f "artifacts/$(params.output-html-name)" ]; then
              echo "✅ HTML output: $(du -h artifacts/$(params.output-html-name) | cut -f1)"
            else
              echo "❌ HTML output missing"
              exit 1
            fi
            
            # Check results file
            if [ -f "artifacts/demo_results.json" ]; then
              echo "✅ Results file: $(du -h artifacts/demo_results.json | cut -f1)"
              echo "📊 Results content:"
              cat artifacts/demo_results.json
            else
              echo "⚠️ Results file missing (optional)"
            fi
            
            echo ""
            echo "🎉 GPU Scientific Computing Pipeline Demo SUCCESSFUL!"
            echo "✅ All components working correctly:"
            echo "   - Environment preparation"
            echo "   - GPU-accelerated notebook execution"
            echo "   - HTML conversion"
            echo "   - Results verification"
  
  workspaces:
  - name: shared-artifacts-workspace
    persistentVolumeClaim:
      claimName: shared-artifacts-workspace
  
  timeouts:
    pipeline: "1h"
  
  taskRunTemplate:
    podTemplate:
      nodeSelector:
        accelerator: nvidia-tesla-gpu
      tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule
      securityContext:
        fsGroup: 0
        runAsUser: 0 
# 00 - Kubernetes å•èŠ‚ç‚¹é›†ç¾¤å®‰è£…æŒ‡å—

## æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›åœ¨ Ubuntu 24.04 LTS ç³»ç»Ÿä¸Šå®‰è£…å•èŠ‚ç‚¹ Kubernetes é›†ç¾¤çš„å®Œæ•´æŒ‡å—ã€‚è¯¥å®‰è£…æ–¹æ¡ˆé‡‡ç”¨ç”Ÿäº§çº§é…ç½®ï¼ŒåŒ…å«å®Œæ•´çš„ç›‘æ§ã€å­˜å‚¨ã€ç½‘ç»œå’Œ GPU æ”¯æŒï¼Œé€‚åˆå¼€å‘ã€æµ‹è¯•å’Œå°è§„æ¨¡ç”Ÿäº§ç¯å¢ƒä½¿ç”¨ã€‚

## æŠ€æœ¯æ ˆé€‰æ‹©

ç»è¿‡æŠ€æœ¯è¯„ä¼°ï¼Œæœ¬å®‰è£…é‡‡ç”¨ä»¥ä¸‹æŠ€æœ¯æ ˆï¼š

- **å®¹å™¨è¿è¡Œæ—¶**: containerd (CNCF æ¯•ä¸šé¡¹ç›®ï¼Œå®˜æ–¹æ¨è)
- **Kubernetes ç‰ˆæœ¬**: v1.30.x (ç¨³å®šç‰ˆæœ¬ï¼Œç”Ÿäº§å°±ç»ª)
- **ç½‘ç»œæ’ä»¶**: Flannel (ç®€å•å¯é ï¼Œé€‚åˆå•èŠ‚ç‚¹)
- **å­˜å‚¨**: local-path-provisioner (å•èŠ‚ç‚¹å­˜å‚¨è§£å†³æ–¹æ¡ˆ)
- **å…¥å£æ§åˆ¶å™¨**: NGINX Ingress Controller (è¡Œä¸šæ ‡å‡†)
- **ç›‘æ§æ–¹æ¡ˆ**: Prometheus + Grafana (å®Œæ•´ç›‘æ§ç”Ÿæ€)
- **ä»ªè¡¨æ¿**: Kubernetes Dashboard (å®˜æ–¹ä»ªè¡¨æ¿)
- **GPU æ”¯æŒ**: NVIDIA GPU Operator (å®˜æ–¹ GPU ç®¡ç†æ–¹æ¡ˆ)

## ç³»ç»Ÿè¦æ±‚

### ç¡¬ä»¶è¦æ±‚
- **CPU**: æœ€å°‘ 4 æ ¸å¿ƒï¼ˆæ¨è 8 æ ¸å¿ƒï¼‰
- **å†…å­˜**: æœ€å°‘ 8GB RAMï¼ˆæ¨è 16GB æˆ–ä»¥ä¸Šï¼‰
- **å­˜å‚¨**: æœ€å°‘ 50GB å¯ç”¨ç£ç›˜ç©ºé—´ï¼ˆæ¨è 100GBï¼‰
- **ç½‘ç»œ**: ç¨³å®šçš„ç½‘ç»œè¿æ¥
- **GPU**: NVIDIA GPUï¼ˆå¯é€‰ï¼Œæœ¬ç¯å¢ƒæœ‰ 4x NVIDIA A16ï¼‰

### è½¯ä»¶è¦æ±‚
- Ubuntu 24.04 LTS (Noble Numbat)
- Root æˆ– sudo æƒé™
- äº’è”ç½‘è¿æ¥

## ç¬¬ä¸€éƒ¨åˆ†ï¼šç³»ç»Ÿå‰ç½®æ¡ä»¶å‡†å¤‡

### 1.1 ç³»ç»Ÿä¿¡æ¯éªŒè¯

é¦–å…ˆéªŒè¯å½“å‰ç³»ç»Ÿé…ç½®ï¼š

```bash
# æ£€æŸ¥ç³»ç»Ÿç‰ˆæœ¬
lsb_release -a

# æ£€æŸ¥å†…æ ¸ç‰ˆæœ¬
uname -r

# æ£€æŸ¥ç³»ç»Ÿèµ„æº
free -h
df -h

# æ£€æŸ¥ GPU ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
nvidia-smi
```

**éªŒè¯æ–¹æ³•**ï¼š
- ç¡®è®¤è¾“å‡ºæ˜¾ç¤º Ubuntu 24.04
- å†…æ ¸ç‰ˆæœ¬åº”ä¸º 6.x ç³»åˆ—
- å¯ç”¨å†…å­˜è‡³å°‘ 8GB
- æ ¹åˆ†åŒºè‡³å°‘æœ‰ 50GB å¯ç”¨ç©ºé—´
- GPU ä¿¡æ¯æ­£å¸¸æ˜¾ç¤º

### 1.2 æ›´æ–°ç³»ç»ŸåŒ…

```bash
# æ›´æ–°åŒ…ç´¢å¼•
sudo apt update

# å‡çº§æ‰€æœ‰åŒ…åˆ°æœ€æ–°ç‰ˆæœ¬
sudo apt upgrade -y

# å®‰è£…å¿…è¦çš„å·¥å…·åŒ…
sudo apt install -y curl wget gnupg2 software-properties-common apt-transport-https ca-certificates lsb-release
```

**éªŒè¯æ–¹æ³•**ï¼š
```bash
# æ£€æŸ¥å…³é”®å·¥å…·æ˜¯å¦å®‰è£…æˆåŠŸ
which curl wget gnupg2
curl --version
```

### 1.3 é…ç½®ç³»ç»Ÿå‚æ•°

#### 1.3.1 ç¦ç”¨ Swap

Kubernetes è¦æ±‚ç¦ç”¨ swap ä»¥ç¡®ä¿æ€§èƒ½ï¼š

```bash
# ä¸´æ—¶ç¦ç”¨ swap
sudo swapoff -a

# æ°¸ä¹…ç¦ç”¨ swap
sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab
```

**éªŒè¯æ–¹æ³•**ï¼š
```bash
# æ£€æŸ¥ swap æ˜¯å¦å·²ç¦ç”¨
free -h
# Swap è¡Œåº”æ˜¾ç¤ºå…¨éƒ¨ä¸º 0

# æ£€æŸ¥ fstab é…ç½®
grep swap /etc/fstab
# swap è¡Œåº”è¢«æ³¨é‡Šæ‰
```

#### 1.3.2 åŠ è½½å¿…è¦çš„å†…æ ¸æ¨¡å—

```bash
# åˆ›å»ºå†…æ ¸æ¨¡å—é…ç½®æ–‡ä»¶
cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

# ç«‹å³åŠ è½½æ¨¡å—
sudo modprobe overlay
sudo modprobe br_netfilter
```

**éªŒè¯æ–¹æ³•**ï¼š
```bash
# æ£€æŸ¥æ¨¡å—æ˜¯å¦åŠ è½½æˆåŠŸ
lsmod | grep overlay
lsmod | grep br_netfilter
```

#### 1.3.3 é…ç½®ç³»ç»Ÿå†…æ ¸å‚æ•°

```bash
# åˆ›å»º sysctl é…ç½®æ–‡ä»¶
cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF

# åº”ç”¨é…ç½®
sudo sysctl --system
```

**éªŒè¯æ–¹æ³•**ï¼š
```bash
# æ£€æŸ¥å‚æ•°æ˜¯å¦æ­£ç¡®è®¾ç½®
sysctl net.bridge.bridge-nf-call-iptables
sysctl net.bridge.bridge-nf-call-ip6tables  
sysctl net.ipv4.ip_forward
# æ‰€æœ‰å€¼éƒ½åº”è¯¥ä¸º 1
```

### 1.4 é…ç½®é˜²ç«å¢™

ä¸º Kubernetes ç»„ä»¶å¼€æ”¾å¿…è¦çš„ç«¯å£ï¼š

```bash
# å¦‚æœä½¿ç”¨ ufwï¼ˆUbuntu é»˜è®¤é˜²ç«å¢™ï¼‰
sudo ufw allow 6443/tcp    # Kubernetes API server
sudo ufw allow 2379:2380/tcp # etcd server client API
sudo ufw allow 10250/tcp   # Kubelet API
sudo ufw allow 10251/tcp   # kube-scheduler
sudo ufw allow 10252/tcp   # kube-controller-manager
sudo ufw allow 10255/tcp   # Read-only Kubelet API
sudo ufw allow 30000:32767/tcp # NodePort Services

# å…è®¸å®¹å™¨ç½‘ç»œé€šä¿¡
sudo ufw allow from 10.244.0.0/16  # Pod ç½‘ç»œï¼ˆFlannelï¼‰
sudo ufw allow from 10.96.0.0/12   # Service ç½‘ç»œ
```

**éªŒè¯æ–¹æ³•**ï¼š
```bash
# æ£€æŸ¥é˜²ç«å¢™è§„åˆ™
sudo ufw status numbered
```

## ç¬¬äºŒéƒ¨åˆ†ï¼šå®¹å™¨è¿è¡Œæ—¶å®‰è£…é…ç½®

### 2.1 å®‰è£… containerd

#### 2.1.1 æ·»åŠ  Docker å®˜æ–¹ä»“åº“

```bash
# åˆ›å»º keyrings ç›®å½•
sudo mkdir -p /etc/apt/keyrings

# æ·»åŠ  Docker çš„å®˜æ–¹ GPG å¯†é’¥
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg

# è®¾ç½®ä»“åº“
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
  $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
```

#### 2.1.2 å®‰è£… containerd

```bash
# æ›´æ–°åŒ…ç´¢å¼•
sudo apt update

# å®‰è£… containerd
sudo apt install -y containerd.io

# å¯åŠ¨å¹¶å¯ç”¨ containerd æœåŠ¡
sudo systemctl enable containerd
sudo systemctl start containerd
```

**éªŒè¯æ–¹æ³•**ï¼š
```bash
# æ£€æŸ¥ containerd ç‰ˆæœ¬å’ŒçŠ¶æ€
containerd --version
sudo systemctl status containerd
```

### 2.2 é…ç½® containerd

#### 2.2.1 ç”Ÿæˆé»˜è®¤é…ç½®

```bash
# åˆ›å»ºé…ç½®ç›®å½•
sudo mkdir -p /etc/containerd

# ç”Ÿæˆé»˜è®¤é…ç½®
containerd config default | sudo tee /etc/containerd/config.toml

# å¤‡ä»½é…ç½®æ–‡ä»¶
sudo cp /etc/containerd/config.toml /etc/containerd/config.toml.backup
```

#### 2.2.2 é…ç½® systemd cgroup é©±åŠ¨

```bash
# ä¿®æ”¹ systemd cgroup é…ç½®
sudo sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' /etc/containerd/config.toml
```

**éªŒè¯æ–¹æ³•**ï¼š
```bash
# æ£€æŸ¥é…ç½®æ˜¯å¦æ­£ç¡®ä¿®æ”¹
grep -A 5 -B 5 "SystemdCgroup" /etc/containerd/config.toml
```

#### 2.2.3 é‡å¯ containerd

```bash
# é‡å¯æœåŠ¡ä»¥åº”ç”¨æ–°é…ç½®
sudo systemctl restart containerd

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
sudo systemctl status containerd
```

**é‡è¦æç¤º**: å¦‚æœ kubeadm init æ—¶é‡åˆ° CRI é”™è¯¯ï¼Œéœ€è¦é‡å¯ containerd æœåŠ¡ï¼š
```bash
# å¦‚æœé‡åˆ° "container runtime is not running" é”™è¯¯
sudo systemctl restart containerd

# éªŒè¯ CRI æ¥å£æ˜¯å¦æ­£å¸¸
sudo crictl --runtime-endpoint unix:///var/run/containerd/containerd.sock version
```

### 2.3 å®‰è£… CNI æ’ä»¶

```bash
# åˆ›å»º CNI ç›®å½•
sudo mkdir -p /opt/cni/bin

# ä¸‹è½½ CNI æ’ä»¶
CNI_VERSION="v1.3.0"
curl -L "https://github.com/containernetworking/plugins/releases/download/${CNI_VERSION}/cni-plugins-linux-amd64-${CNI_VERSION}.tgz" | sudo tar -C /opt/cni/bin -xz
```

**éªŒè¯æ–¹æ³•**ï¼š
```bash
# æ£€æŸ¥ CNI æ’ä»¶æ˜¯å¦å®‰è£…æˆåŠŸ
ls -la /opt/cni/bin/
```

## ç¬¬ä¸‰éƒ¨åˆ†ï¼šKubernetes å·¥å…·å®‰è£…

### 3.1 å®‰è£… kubeadm, kubelet, kubectl

#### 3.1.1 æ·»åŠ  Kubernetes ä»“åº“

```bash
# æ·»åŠ  Kubernetes ç­¾åå¯†é’¥
curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.30/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg

# æ·»åŠ  Kubernetes ä»“åº“
echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.30/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list
```

#### 3.1.2 å®‰è£… Kubernetes å·¥å…·

```bash
# æ›´æ–°åŒ…ç´¢å¼•
sudo apt update

# å®‰è£… Kubernetes å·¥å…·
sudo apt install -y kubelet kubeadm kubectl

# é˜²æ­¢è‡ªåŠ¨æ›´æ–°
sudo apt-mark hold kubelet kubeadm kubectl
```

**éªŒè¯æ–¹æ³•**ï¼š
```bash
# æ£€æŸ¥ç‰ˆæœ¬
kubeadm version
kubelet --version
kubectl version --client
```

### 3.2 é…ç½® kubelet

```bash
# å¯ç”¨ kubelet æœåŠ¡
sudo systemctl enable kubelet
```

## ç¬¬å››éƒ¨åˆ†ï¼šåˆå§‹åŒ– Kubernetes é›†ç¾¤

### 4.1 åˆ›å»ºé›†ç¾¤é…ç½®æ–‡ä»¶

åˆ›å»º kubeadm é…ç½®æ–‡ä»¶ä»¥è‡ªå®šä¹‰é›†ç¾¤å‚æ•°ï¼š

```bash
cat <<EOF | sudo tee /tmp/kubeadm-config.yaml
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
kubernetesVersion: v1.30.0
controlPlaneEndpoint: "$(hostname -I | awk '{print $1}'):6443"
networking:
  serviceSubnet: "10.96.0.0/12"
  podSubnet: "10.244.0.0/16"
  dnsDomain: "cluster.local"
---
apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: "$(hostname -I | awk '{print $1}')"
  bindPort: 6443
nodeRegistration:
  criSocket: unix:///var/run/containerd/containerd.sock
  kubeletExtraArgs:
    cgroup-driver: "systemd"
    container-runtime-endpoint: "unix:///var/run/containerd/containerd.sock"
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
cgroupDriver: systemd
containerRuntimeEndpoint: "unix:///var/run/containerd/containerd.sock"
EOF
```

### 4.2 åˆå§‹åŒ–é›†ç¾¤

```bash
# åˆå§‹åŒ– Kubernetes é›†ç¾¤
sudo kubeadm init --config=/tmp/kubeadm-config.yaml

# è®°å½•è¾“å‡ºçš„ join å‘½ä»¤ï¼ˆè™½ç„¶æ˜¯å•èŠ‚ç‚¹ï¼Œä½†å»ºè®®ä¿å­˜ï¼‰
```

**é‡è¦**: ä¿å­˜è¾“å‡ºä¸­çš„ kubeadm join å‘½ä»¤ï¼Œä»¥å¤‡å°†æ¥æ·»åŠ èŠ‚ç‚¹ä½¿ç”¨ã€‚

### 4.3 é…ç½® kubectl

```bash
# ä¸ºå½“å‰ç”¨æˆ·é…ç½® kubectl
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
```

**éªŒè¯æ–¹æ³•**ï¼š
```bash
# æ£€æŸ¥é›†ç¾¤çŠ¶æ€
kubectl cluster-info
kubectl get nodes
```

### 4.4 ç§»é™¤ master èŠ‚ç‚¹æ±¡ç‚¹ï¼ˆå•èŠ‚ç‚¹é…ç½®ï¼‰

```bash
# å…è®¸åœ¨ master èŠ‚ç‚¹ä¸Šè°ƒåº¦ Pod
kubectl taint nodes --all node-role.kubernetes.io/control-plane-
```

**éªŒè¯æ–¹æ³•**ï¼š
```bash
# æ£€æŸ¥èŠ‚ç‚¹çŠ¶æ€
kubectl get nodes
# çŠ¶æ€åº”è¯¥ä¸º Readyï¼Œä½†ç½‘ç»œæ’ä»¶å®‰è£…å‰å¯èƒ½æ˜¾ç¤º NotReady
```

## ç¬¬äº”éƒ¨åˆ†ï¼šç½‘ç»œæ’ä»¶å®‰è£…ï¼ˆFlannelï¼‰

### 5.1 å®‰è£… Flannel

```bash
# ä¸‹è½½å¹¶å®‰è£… Flannel
kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml
```

**éªŒè¯æ–¹æ³•**ï¼š
```bash
# æ£€æŸ¥ Flannel Pod çŠ¶æ€
kubectl get pods -n kube-flannel

# æ£€æŸ¥èŠ‚ç‚¹çŠ¶æ€ï¼ˆåº”è¯¥å˜ä¸º Readyï¼‰
kubectl get nodes

# æ£€æŸ¥æ‰€æœ‰ç³»ç»Ÿ Pod çŠ¶æ€
kubectl get pods -A
```

### 5.2 éªŒè¯ç½‘ç»œè¿é€šæ€§

```bash
# åˆ›å»ºæµ‹è¯• Pod
kubectl run test-pod --image=busybox --restart=Never --rm -it -- /bin/sh

# åœ¨ Pod å†…æµ‹è¯•ï¼ˆåœ¨ Pod shell ä¸­æ‰§è¡Œï¼‰
nslookup kubernetes.default.svc.cluster.local
ping -c 3 8.8.8.8
exit
```

## ç¬¬å…­éƒ¨åˆ†ï¼šå­˜å‚¨é…ç½®ï¼ˆlocal-path-provisionerï¼‰

### 6.1 å®‰è£… local-path-provisioner

```bash
# å®‰è£… local-path-provisioner
kubectl apply -f https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.24/deploy/local-path-storage.yaml
```

**éªŒè¯æ–¹æ³•**ï¼š
```bash
# æ£€æŸ¥å­˜å‚¨ç±»
kubectl get storageclass

# æ£€æŸ¥ local-path-provisioner Pod
kubectl get pods -n local-path-storage
```

### 6.2 è®¾ç½®é»˜è®¤å­˜å‚¨ç±»

```bash
# è®¾ç½® local-path ä¸ºé»˜è®¤å­˜å‚¨ç±»
kubectl patch storageclass local-path -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'
```

**éªŒè¯æ–¹æ³•**ï¼š
```bash
# æ£€æŸ¥é»˜è®¤å­˜å‚¨ç±»ï¼ˆåº”è¯¥çœ‹åˆ° local-path (default)ï¼‰
kubectl get storageclass
```

### 6.3 æµ‹è¯•å­˜å‚¨åŠŸèƒ½

```bash
# åˆ›å»ºæµ‹è¯• PVC
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: test-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
EOF

# åˆ›å»ºä½¿ç”¨ PVC çš„æµ‹è¯• Pod
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: test-storage-pod
spec:
  containers:
  - name: test-container
    image: busybox
    command: ['sh', '-c', 'echo "Hello Storage" > /data/test.txt && sleep 3600']
    volumeMounts:
    - name: test-volume
      mountPath: /data
  volumes:
  - name: test-volume
    persistentVolumeClaim:
      claimName: test-pvc
EOF
```

**éªŒè¯æ–¹æ³•**ï¼š
```bash
# æ£€æŸ¥ PVC çŠ¶æ€
kubectl get pvc

# æ£€æŸ¥ Pod çŠ¶æ€
kubectl get pods

# éªŒè¯æ•°æ®å†™å…¥
kubectl exec test-storage-pod -- cat /data/test.txt

# æ¸…ç†æµ‹è¯•èµ„æº
kubectl delete pod test-storage-pod
kubectl delete pvc test-pvc
```

## ç¬¬ä¸ƒéƒ¨åˆ†ï¼šNGINX Ingress Controller å®‰è£…

### 7.1 å®‰è£… NGINX Ingress Controller

```bash
# å®‰è£… NGINX Ingress Controller
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.2/deploy/static/provider/baremetal/deploy.yaml
```

**éªŒè¯æ–¹æ³•**ï¼š
```bash
# æ£€æŸ¥ Ingress Controller Pod çŠ¶æ€
kubectl get pods -n ingress-nginx

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
kubectl get svc -n ingress-nginx
```

### 7.2 é…ç½® Ingress Controller ä¸º NodePort

```bash
# æ£€æŸ¥ NodePort ç«¯å£
kubectl get svc -n ingress-nginx ingress-nginx-controller

# è®°å½• HTTP å’Œ HTTPS ç«¯å£ï¼ˆé€šå¸¸æ˜¯ 30000+ èŒƒå›´ï¼‰
```

### 7.3 ç”Ÿæˆè‡ªç­¾åè¯ä¹¦

```bash
# åˆ›å»ºè¯ä¹¦ç›®å½•
mkdir -p ~/k8s-certs
cd ~/k8s-certs

# ç”Ÿæˆç§é’¥
openssl genrsa -out tls.key 2048

# ç”Ÿæˆè¯ä¹¦ç­¾åè¯·æ±‚
openssl req -new -key tls.key -out tls.csr -subj "/CN=k8s.local/O=kubernetes"

# ç”Ÿæˆè‡ªç­¾åè¯ä¹¦
openssl x509 -req -in tls.csr -signkey tls.key -out tls.crt -days 365

# åˆ›å»º TLS Secret
kubectl create secret tls k8s-local-tls --cert=tls.crt --key=tls.key -n default
```

### 7.4 æµ‹è¯• Ingress

```bash
# åˆ›å»ºæµ‹è¯•åº”ç”¨
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: test-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: test-app
  template:
    metadata:
      labels:
        app: test-app
    spec:
      containers:
      - name: test-app
        image: nginx:1.21
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: test-app-service
spec:
  selector:
    app: test-app
  ports:
  - port: 80
    targetPort: 80
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: test-app-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  tls:
  - hosts:
    - k8s.local
    secretName: k8s-local-tls
  rules:
  - host: k8s.local
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: test-app-service
            port:
              number: 80
EOF
```

**éªŒè¯æ–¹æ³•**ï¼š
```bash
# æ£€æŸ¥ Ingress çŠ¶æ€
kubectl get ingress

# æ·»åŠ æœ¬åœ° hosts æ¡ç›®
echo "127.0.0.1 k8s.local" | sudo tee -a /etc/hosts

# è·å– NodePort ç«¯å£
HTTPS_PORT=$(kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath='{.spec.ports[?(@.name=="https")].nodePort}')

# æµ‹è¯•è®¿é—®ï¼ˆå¿½ç•¥è¯ä¹¦è­¦å‘Šï¼‰
curl -k https://k8s.local:$HTTPS_PORT

# æ¸…ç†æµ‹è¯•èµ„æº
kubectl delete deployment test-app
kubectl delete service test-app-service
kubectl delete ingress test-app-ingress
```

## ç¬¬å…«éƒ¨åˆ†ï¼šç›‘æ§ç³»ç»Ÿå®‰è£…ï¼ˆPrometheus + Grafanaï¼‰

### 8.1 å®‰è£… kube-prometheus-stack

```bash
# æ·»åŠ  Prometheus Helm ä»“åº“
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

# æ·»åŠ  Prometheus ç¤¾åŒº Helm ä»“åº“
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update
```

### 8.2 åˆ›å»ºç›‘æ§å‘½åç©ºé—´

```bash
# åˆ›å»ºç›‘æ§å‘½åç©ºé—´
kubectl create namespace monitoring
```

### 8.3 å®‰è£… Prometheus å’Œ Grafana

```bash
# åˆ›å»ºé…ç½®æ–‡ä»¶ç›®å½•
mkdir -p configs/monitoring

# åˆ›å»º values é…ç½®æ–‡ä»¶
cat <<EOF > configs/monitoring/prometheus-values.yaml
prometheus:
  prometheusSpec:
    serviceMonitorSelectorNilUsesHelmValues: false
    podMonitorSelectorNilUsesHelmValues: false
    ruleSelectorNilUsesHelmValues: false
    storageSpec:
      volumeClaimTemplate:
        spec:
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 10Gi

grafana:
  adminPassword: "admin123"
  persistence:
    enabled: true
    size: 5Gi
  service:
    type: NodePort
    nodePort: 32000

alertmanager:
  alertmanagerSpec:
    storage:
      volumeClaimTemplate:
        spec:
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 5Gi
EOF

# å®‰è£… kube-prometheus-stack (è®¾ç½® Grafana å¯†ç ä¸º admin123)
helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring \
  --values configs/monitoring/prometheus-values.yaml \
  --set grafana.adminPassword=admin123
```

**éªŒè¯æ–¹æ³•**ï¼š
```bash
# æ£€æŸ¥æ‰€æœ‰ç›‘æ§ç»„ä»¶çŠ¶æ€
kubectl get pods -n monitoring

# æ£€æŸ¥æœåŠ¡
kubectl get svc -n monitoring

# è·å– Grafana è®¿é—®ç«¯å£
kubectl get svc -n monitoring prometheus-grafana -o jsonpath='{.spec.ports[0].nodePort}'
```

### 8.4 é…ç½® Grafana è®¿é—®

```bash
# è·å– Grafana NodePort
GRAFANA_PORT=$(kubectl get svc -n monitoring prometheus-grafana -o jsonpath='{.spec.ports[0].nodePort}')

echo "Grafana è®¿é—®åœ°å€: http://$(hostname -I | awk '{print $1}'):$GRAFANA_PORT"
echo "ç”¨æˆ·å: admin"
echo "å¯†ç : admin123"
```

### 8.5 éªŒè¯ç›‘æ§æ•°æ®

```bash
# è·å– Prometheus è®¿é—®ç«¯å£
PROMETHEUS_PORT=$(kubectl get svc -n monitoring prometheus-kube-prometheus-prometheus -o jsonpath='{.spec.ports[0].nodePort}')

echo "Prometheus è®¿é—®åœ°å€: http://$(hostname -I | awk '{print $1}'):$PROMETHEUS_PORT"
```

## ç¬¬ä¹éƒ¨åˆ†ï¼šKubernetes Dashboard å®‰è£…

### 9.1 å®‰è£… Kubernetes Dashboard

```bash
# å®‰è£… Kubernetes Dashboard
kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml
```

### 9.2 åˆ›å»ºç®¡ç†å‘˜ç”¨æˆ·

```bash
# åˆ›å»ºæœåŠ¡è´¦æˆ·
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: ServiceAccount
metadata:
  name: dashboard-admin
  namespace: kubernetes-dashboard
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: dashboard-admin
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: dashboard-admin
  namespace: kubernetes-dashboard
EOF
```

### 9.3 é…ç½® Dashboard è®¿é—®

```bash
# ä¿®æ”¹æœåŠ¡ç±»å‹ä¸º NodePort
kubectl patch svc kubernetes-dashboard -n kubernetes-dashboard -p '{"spec":{"type":"NodePort"}}'

# è·å–è®¿é—®ç«¯å£
DASHBOARD_PORT=$(kubectl get svc -n kubernetes-dashboard kubernetes-dashboard -o jsonpath='{.spec.ports[0].nodePort}')

echo "Dashboard è®¿é—®åœ°å€: https://$(hostname -I | awk '{print $1}'):$DASHBOARD_PORT"
```

### 9.4 è·å–è®¿é—®ä»¤ç‰Œ

```bash
# åˆ›å»ºé•¿æœŸæœ‰æ•ˆçš„è®¿é—®ä»¤ç‰Œ (1å¹´æœ‰æ•ˆæœŸ)
kubectl create token dashboard-admin -n kubernetes-dashboard --duration=8760h

# ä¿å­˜ä»¤ç‰Œåˆ°æ–‡ä»¶ (å¯é€‰)
kubectl create token dashboard-admin -n kubernetes-dashboard --duration=8760h > dashboard-token.txt
```

**éªŒè¯æ–¹æ³•**ï¼š
- ä½¿ç”¨æµè§ˆå™¨è®¿é—® Dashboard URL
- é€‰æ‹© "Token" ç™»å½•æ–¹å¼
- è¾“å…¥è·å–çš„ä»¤ç‰Œ
- æˆåŠŸç™»å½•å¹¶çœ‹åˆ°é›†ç¾¤æ¦‚è§ˆ

## ç¬¬åéƒ¨åˆ†ï¼šGPU æ”¯æŒé…ç½®ï¼ˆNVIDIA GPU Operatorï¼‰

### 10.1 éªŒè¯ GPU é©±åŠ¨

```bash
# æ£€æŸ¥ NVIDIA é©±åŠ¨çŠ¶æ€
nvidia-smi

# æ£€æŸ¥ NVIDIA å®¹å™¨å·¥å…·åŒ…ï¼ˆå¦‚æœéœ€è¦å®‰è£…ï¼‰
which nvidia-container-runtime || echo "éœ€è¦å®‰è£… nvidia-container-toolkit"
```

### 10.2 å®‰è£… NVIDIA Container Toolkit

```bash
# æ·»åŠ  NVIDIA ä»“åº“ GPG å¯†é’¥
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg

# æ·»åŠ  NVIDIA ä»“åº“
curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list

# å®‰è£… nvidia-container-toolkit
sudo apt update
sudo apt install -y nvidia-container-toolkit

# é…ç½® containerd
sudo nvidia-ctk runtime configure --runtime=containerd
sudo systemctl restart containerd
```

### 10.3 å®‰è£… NVIDIA GPU Operator

```bash
# æ·»åŠ  NVIDIA Helm ä»“åº“
helm repo add nvidia https://helm.ngc.nvidia.com/nvidia
helm repo update

# åˆ›å»º GPU Operator å‘½åç©ºé—´
kubectl create namespace gpu-operator

# å®‰è£… GPU Operator
helm install gpu-operator nvidia/gpu-operator \
  --namespace gpu-operator \
  --set driver.enabled=false \
  --set toolkit.enabled=true
```

**éªŒè¯æ–¹æ³•**ï¼š
```bash
# æ£€æŸ¥ GPU Operator ç»„ä»¶çŠ¶æ€
kubectl get pods -n gpu-operator

# ç­‰å¾…æ‰€æœ‰ Pod å°±ç»ªï¼ˆå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰
kubectl wait --for=condition=Ready pod --all -n gpu-operator --timeout=600s
```

### 10.4 éªŒè¯ GPU åŠŸèƒ½

```bash
# åˆ›å»º GPU æµ‹è¯• Pod
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: gpu-test
spec:
  containers:
  - name: gpu-test
    image: nvidia/cuda:11.8-base-ubuntu20.04
    command: ["nvidia-smi"]
    resources:
      limits:
        nvidia.com/gpu: 1
  restartPolicy: Never
EOF

# ç­‰å¾… Pod å®Œæˆ
kubectl wait --for=condition=Ready pod/gpu-test --timeout=300s

# æŸ¥çœ‹ GPU æµ‹è¯•ç»“æœ
kubectl logs gpu-test

# æ¸…ç†æµ‹è¯• Pod
kubectl delete pod gpu-test
```

### 10.5 éƒ¨ç½² GPU ç›‘æ§

```bash
# GPU Operator ä¼šè‡ªåŠ¨éƒ¨ç½² DCGM Exporter ç”¨äº GPU ç›‘æ§
# æ£€æŸ¥ DCGM Exporter çŠ¶æ€
kubectl get pods -n gpu-operator | grep dcgm

# æ£€æŸ¥ GPU æŒ‡æ ‡
kubectl get --raw /api/v1/nodes/$(kubectl get nodes -o name | cut -d/ -f2)/proxy/metrics | grep DCGM
```

## ç¬¬åä¸€éƒ¨åˆ†ï¼šç³»ç»ŸéªŒè¯å’Œæµ‹è¯•

### 11.1 å…¨é¢é›†ç¾¤çŠ¶æ€æ£€æŸ¥

```bash
# æ£€æŸ¥æ‰€æœ‰èŠ‚ç‚¹çŠ¶æ€
kubectl get nodes -o wide

# æ£€æŸ¥æ‰€æœ‰å‘½åç©ºé—´çš„ Pod çŠ¶æ€
kubectl get pods -A

# æ£€æŸ¥æ‰€æœ‰æœåŠ¡çŠ¶æ€
kubectl get svc -A

# æ£€æŸ¥å­˜å‚¨ç±»
kubectl get storageclass

# æ£€æŸ¥ Ingress çŠ¶æ€
kubectl get ingress -A
```

### 11.2 ç½‘ç»œè¿é€šæ€§æµ‹è¯•

```bash
# åˆ›å»ºç½‘ç»œæµ‹è¯• Pod
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: network-test
spec:
  containers:
  - name: network-test
    image: busybox
    command: ['sleep', '3600']
EOF

# ç­‰å¾… Pod å°±ç»ª
kubectl wait --for=condition=Ready pod/network-test --timeout=300s

# æµ‹è¯•å†…éƒ¨ DNS è§£æ
kubectl exec network-test -- nslookup kubernetes.default.svc.cluster.local

# æµ‹è¯•å¤–éƒ¨ç½‘ç»œ
kubectl exec network-test -- wget -q --spider http://www.google.com && echo "å¤–ç½‘è¿é€šæ­£å¸¸"

# æ¸…ç†æµ‹è¯• Pod
kubectl delete pod network-test
```

### 11.3 å­˜å‚¨åŠŸèƒ½æµ‹è¯•

```bash
# åˆ›å»ºå­˜å‚¨æµ‹è¯•
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: storage-test-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 2Gi
---
apiVersion: v1
kind: Pod
metadata:
  name: storage-test
spec:
  containers:
  - name: storage-test
    image: busybox
    command: ['sh', '-c', 'echo "å­˜å‚¨æµ‹è¯•æ•°æ®" > /data/test.txt && cat /data/test.txt && sleep 300']
    volumeMounts:
    - name: storage-volume
      mountPath: /data
  volumes:
  - name: storage-volume
    persistentVolumeClaim:
      claimName: storage-test-pvc
EOF

# æ£€æŸ¥æµ‹è¯•ç»“æœ
kubectl logs storage-test

# æ¸…ç†æµ‹è¯•èµ„æº
kubectl delete pod storage-test
kubectl delete pvc storage-test-pvc
```

### 11.4 GPU è´Ÿè½½æµ‹è¯•

```bash
# åˆ›å»º GPU è´Ÿè½½æµ‹è¯•
cat <<EOF | kubectl apply -f -
apiVersion: batch/v1
kind: Job
metadata:
  name: gpu-benchmark
spec:
  template:
    spec:
      containers:
      - name: gpu-benchmark
        image: nvidia/cuda:11.8-devel-ubuntu20.04
        command: ["sh", "-c"]
        args:
        - |
          nvidia-smi
          echo "è¿è¡Œ GPU åŸºå‡†æµ‹è¯•..."
          # ç®€å•çš„ GPU è®¡ç®—æµ‹è¯•
          echo 'import numpy as np; print("GPU æµ‹è¯•å®Œæˆ")' > test.py
          python3 test.py || echo "Python3 not available, test completed with nvidia-smi"
        resources:
          limits:
            nvidia.com/gpu: 1
      restartPolicy: Never
EOF

# ç­‰å¾…ä»»åŠ¡å®Œæˆ
kubectl wait --for=condition=Complete job/gpu-benchmark --timeout=600s

# æŸ¥çœ‹æµ‹è¯•ç»“æœ
kubectl logs job/gpu-benchmark

# æ¸…ç†æµ‹è¯•ä»»åŠ¡
kubectl delete job gpu-benchmark
```

### 11.5 ç›‘æ§ç³»ç»ŸéªŒè¯

```bash
# æ£€æŸ¥ Prometheus ç›®æ ‡çŠ¶æ€
PROMETHEUS_PORT=$(kubectl get svc -n monitoring prometheus-kube-prometheus-prometheus -o jsonpath='{.spec.ports[0].nodePort}')
echo "è®¿é—® Prometheus targets: http://$(hostname -I | awk '{print $1}'):$PROMETHEUS_PORT/targets"

# æ£€æŸ¥ Grafana ä»ªè¡¨æ¿
GRAFANA_PORT=$(kubectl get svc -n monitoring prometheus-grafana -o jsonpath='{.spec.ports[0].nodePort}')
echo "è®¿é—® Grafana: http://$(hostname -I | awk '{print $1}'):$GRAFANA_PORT"
echo "ç”¨æˆ·å: admin, å¯†ç : admin123"
```

## ç¬¬åäºŒéƒ¨åˆ†ï¼šæ€§èƒ½ä¼˜åŒ–å’Œå®‰å…¨é…ç½®

### 12.1 ç³»ç»Ÿæ€§èƒ½ä¼˜åŒ–

```bash
# é…ç½®ç³»ç»Ÿé™åˆ¶
cat <<EOF | sudo tee /etc/security/limits.d/k8s.conf
* soft nofile 65536
* hard nofile 65536
* soft nproc 65536
* hard nproc 65536
EOF

# é…ç½®å†…æ ¸å‚æ•°ä¼˜åŒ–
cat <<EOF | sudo tee /etc/sysctl.d/k8s-performance.conf
# ç½‘ç»œä¼˜åŒ–
net.core.somaxconn = 32768
net.core.netdev_max_backlog = 5000
net.ipv4.tcp_max_syn_backlog = 8192
net.ipv4.tcp_max_tw_buckets = 2000000
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_fin_timeout = 30

# å†…å­˜ä¼˜åŒ–
vm.max_map_count = 262144
vm.swappiness = 1
EOF

# åº”ç”¨é…ç½®
sudo sysctl --system
```

### 12.2 å®‰å…¨é…ç½®

```bash
# é…ç½® RBAC æœ€å°æƒé™åŸåˆ™
# ï¼ˆåœ¨å®é™…ç”Ÿäº§ä¸­ï¼Œå»ºè®®ä¸ºä¸åŒåº”ç”¨åˆ›å»ºä¸“ç”¨çš„ ServiceAccountï¼‰

# é…ç½®ç½‘ç»œç­–ç•¥ï¼ˆç¤ºä¾‹ï¼‰
cat <<EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-ingress
  namespace: default
spec:
  podSelector: {}
  policyTypes:
  - Ingress
EOF
```

### 12.3 æ—¥å¿—é…ç½®

```bash
# é…ç½® containerd æ—¥å¿—è½®è½¬
sudo tee /etc/logrotate.d/containerd > /dev/null <<EOF
/var/log/containerd.log {
    daily
    missingok
    rotate 7
    compress
    notifempty
    create 0644 root root
    postrotate
        systemctl reload containerd > /dev/null 2>&1 || true
    endscript
}
EOF
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

#### é—®é¢˜ 1: NodePort æœåŠ¡æ— æ³•è®¿é—®
**ç—‡çŠ¶**: æµè§ˆå™¨è®¿é—® NodePort æœåŠ¡æ—¶æ˜¾ç¤º "è¿æ¥è¢«é‡ç½®" æˆ– "æ— æ³•è®¿é—®"
**è¯Šæ–­**:
```bash
# æ£€æŸ¥ NodePort ç›‘å¬çŠ¶æ€
sudo ss -tlnp | grep -E ":30816|:32000"

# æ£€æŸ¥ kube-proxy çŠ¶æ€
kubectl get pods -n kube-system | grep kube-proxy
kubectl logs -n kube-system $(kubectl get pods -n kube-system | grep kube-proxy | awk '{print $1}')
```
**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ–¹æ¡ˆ 1 (æ¨è): ä½¿ç”¨ Ingress è®¿é—®æœåŠ¡
NODE_IP=$(hostname -I | awk '{print $1}')

# ä¸º Grafana åˆ›å»º Ingress (ä¿®å¤ç‰ˆæœ¬ - ç§»é™¤æœ‰é—®é¢˜çš„ rewrite-target)
cat <<EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: grafana-ingress
  namespace: monitoring
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "false"
spec:
  ingressClassName: nginx
  rules:
  - host: grafana.$NODE_IP.nip.io
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: prometheus-grafana
            port:
              number: 80
EOF

# å¦‚æœ Grafana ä»æ˜¾ç¤º "Page not found"ï¼Œéœ€è¦æ›´æ–° Grafana é…ç½®
cat > /tmp/grafana-values.yaml << 'GRAFANA_EOF'
grafana:
  grafana.ini:
    server:
      domain: grafana.$NODE_IP.nip.io
      root_url: http://grafana.$NODE_IP.nip.io:$INGRESS_HTTP_PORT
      serve_from_sub_path: false
  ingress:
    enabled: false
GRAFANA_EOF

# é€šè¿‡ Helm å‡çº§ Grafana é…ç½®
helm upgrade prometheus prometheus-community/kube-prometheus-stack -n monitoring -f /tmp/grafana-values.yaml

# é…ç½® NGINX Ingress Controller ä½¿ç”¨æ ‡å‡†ç«¯å£ (æ— éœ€ç«¯å£å·è®¿é—®)
kubectl patch deployment ingress-nginx-controller -n ingress-nginx -p '{"spec":{"template":{"spec":{"hostNetwork":true,"dnsPolicy":"ClusterFirstWithHostNet"}}}}'

# ç­‰å¾…é‡å¯å®Œæˆ
kubectl rollout status deployment/ingress-nginx-controller -n ingress-nginx --timeout=120s

# ä¸º Dashboard åˆ›å»º Ingress
cat <<EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: dashboard-ingress
  namespace: kubernetes-dashboard
  annotations:
    nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
    nginx.ingress.kubernetes.io/ssl-passthrough: "true"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
spec:
  ingressClassName: nginx
  tls:
  - hosts:
    - dashboard.$NODE_IP.nip.io
  rules:
  - host: dashboard.$NODE_IP.nip.io
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: kubernetes-dashboard
            port:
              number: 443
EOF

# æœ€ç»ˆè®¿é—®åœ°å€ (æ— ç«¯å£å·ï¼Œä½¿ç”¨æ ‡å‡† 80/443 ç«¯å£):
echo "âœ… æ— ç«¯å£å·è®¿é—®åœ°å€:"
echo "â€¢ Grafana: http://grafana.$NODE_IP.nip.io"
echo "â€¢ Dashboard: https://dashboard.$NODE_IP.nip.io"

# è·å–ç™»å½•å‡­æ®:
echo ""
echo "ğŸ”‘ ç™»å½•ä¿¡æ¯:"
echo "â€¢ Grafana ç”¨æˆ·å: admin"
echo "â€¢ Grafana å¯†ç : admin123"
echo ""
echo "â€¢ Dashboard ä»¤ç‰Œ:"
kubectl create token dashboard-admin -n kubernetes-dashboard --duration=8760h
echo ""

# æ–¹æ¡ˆ 1 å¤‡é€‰: å¦‚æœ NodePort æœ‰é—®é¢˜ï¼Œä½¿ç”¨ kubectl proxy (æœ€å¯é )
cat > ~/kubectl-proxy-services.sh << 'EOF'
#!/bin/bash
echo "=== å¯åŠ¨ kubectl proxy æœåŠ¡ ==="
pkill -f "kubectl proxy" 2>/dev/null
sleep 3
kubectl proxy --address='0.0.0.0' --port=8080 --accept-hosts='.*' > /dev/null 2>&1 &
sleep 5
NODE_IP=$(hostname -I | awk '{print $1}')
echo "âœ… kubectl proxy å·²å¯åŠ¨"
echo "â€¢ Grafana: http://$NODE_IP:8080/api/v1/namespaces/monitoring/services/prometheus-grafana:80/proxy/"
echo "â€¢ Dashboard: http://$NODE_IP:8080/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/"
EOF
chmod +x ~/kubectl-proxy-services.sh && ~/kubectl-proxy-services.sh

# æ–¹æ¡ˆ 2: é‡å¯ kube-proxy
kubectl delete pod -n kube-system $(kubectl get pods -n kube-system | grep kube-proxy | awk '{print $1}')

# æ–¹æ¡ˆ 3: ä½¿ç”¨ç«¯å£è½¬å‘ä½œä¸ºä¸´æ—¶è§£å†³æ–¹æ¡ˆ
kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80 --address=0.0.0.0 &
kubectl port-forward -n kubernetes-dashboard svc/kubernetes-dashboard 8443:443 --address=0.0.0.0 &

# ç„¶åè®¿é—®:
# Grafana: http://èŠ‚ç‚¹IP:3000
# Dashboard: https://èŠ‚ç‚¹IP:8443

# æ–¹æ¡ˆ 4: ä½¿ç”¨è‡ªåŠ¨åŒ–è„šæœ¬ç®¡ç†ç«¯å£è½¬å‘
cat > ~/port-forward-services.sh << 'EOF'
#!/bin/bash
echo "=== å¯åŠ¨ Kubernetes æœåŠ¡ç«¯å£è½¬å‘ ==="
pkill -f "kubectl port-forward" 2>/dev/null
sleep 3
kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80 --address=0.0.0.0 > /dev/null 2>&1 &
kubectl port-forward -n kubernetes-dashboard svc/kubernetes-dashboard 8443:443 --address=0.0.0.0 > /dev/null 2>&1 &
sleep 5
echo "âœ… ç«¯å£è½¬å‘å·²å¯åŠ¨"
echo "â€¢ Grafana: http://$(hostname -I | awk '{print $1}'):3000"
echo "â€¢ Dashboard: https://$(hostname -I | awk '{print $1}'):8443"
EOF

chmod +x ~/port-forward-services.sh
~/port-forward-services.sh
```

**é‡è¦è¯´æ˜**: ç›´æ¥è®¿é—® Kubernetes API Server (6443ç«¯å£) ä¼šè¿”å› 403 é”™è¯¯ï¼Œè¿™æ˜¯æ­£å¸¸çš„å®‰å…¨è¡Œä¸ºã€‚éœ€è¦ä½¿ç”¨ kubectl æˆ–å¸¦æœ‰æ­£ç¡®è®¤è¯çš„å·¥å…·è®¿é—®ã€‚

#### é—®é¢˜ 2: NVIDIA Container Toolkit ä»“åº“é…ç½®é—®é¢˜
**ç—‡çŠ¶**: æ·»åŠ  NVIDIA ä»“åº“æ—¶è¿”å› 404 é”™è¯¯
**è§£å†³æ–¹æ¡ˆ**:
```bash
# ä½¿ç”¨æ–°çš„ä»“åº“é…ç½®æ–¹æ³•
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg

curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
```

#### é—®é¢˜ 3: Pod å¡åœ¨ Pending çŠ¶æ€
**ç—‡çŠ¶**: Pod é•¿æ—¶é—´å¤„äº Pending çŠ¶æ€
**è¯Šæ–­**:
```bash
kubectl describe pod <pod-name>
kubectl get events --sort-by=.metadata.creationTimestamp
```
**è§£å†³æ–¹æ¡ˆ**:
- æ£€æŸ¥èµ„æºé™åˆ¶
- æ£€æŸ¥èŠ‚ç‚¹æ±¡ç‚¹
- æ£€æŸ¥å­˜å‚¨ç±»é…ç½®

#### é—®é¢˜ 2: ç½‘ç»œè¿æ¥é—®é¢˜
**ç—‡çŠ¶**: Pod ä¹‹é—´æ— æ³•é€šä¿¡
**è¯Šæ–­**:
```bash
kubectl get pods -n kube-flannel
kubectl logs -n kube-flannel <flannel-pod>
```
**è§£å†³æ–¹æ¡ˆ**:
- é‡å¯ Flannel Pod
- æ£€æŸ¥é˜²ç«å¢™é…ç½®
- éªŒè¯ CNI æ’ä»¶

#### é—®é¢˜ 3: GPU ä¸å¯è§
**ç—‡çŠ¶**: Pod æ— æ³•è®¿é—® GPU
**è¯Šæ–­**:
```bash
kubectl get nodes -o yaml | grep nvidia.com/gpu
kubectl get pods -n gpu-operator
```
**è§£å†³æ–¹æ¡ˆ**:
- æ£€æŸ¥ NVIDIA é©±åŠ¨
- é‡å¯ GPU Operator ç»„ä»¶
- éªŒè¯ containerd é…ç½®

#### é—®é¢˜ 4: å­˜å‚¨è®¿é—®é—®é¢˜
**ç—‡çŠ¶**: PVC å¡åœ¨ Pending çŠ¶æ€
**è¯Šæ–­**:
```bash
kubectl describe pvc <pvc-name>
kubectl get storageclass
```
**è§£å†³æ–¹æ¡ˆ**:
- æ£€æŸ¥ local-path-provisioner çŠ¶æ€
- éªŒè¯èŠ‚ç‚¹å­˜å‚¨ç©ºé—´
- æ£€æŸ¥æƒé™é…ç½®

### æ—¥å¿—æŸ¥çœ‹å‘½ä»¤

```bash
# æŸ¥çœ‹ kubelet æ—¥å¿—
sudo journalctl -u kubelet -f

# æŸ¥çœ‹ containerd æ—¥å¿—
sudo journalctl -u containerd -f

# æŸ¥çœ‹ Pod æ—¥å¿—
kubectl logs <pod-name> -n <namespace>

# æŸ¥çœ‹å‰ä¸€ä¸ªå®¹å™¨å®ä¾‹çš„æ—¥å¿—
kubectl logs <pod-name> --previous

# æŸ¥çœ‹æ‰€æœ‰å®¹å™¨æ—¥å¿—
kubectl logs <pod-name> --all-containers=true
```

## é›†ç¾¤ç»´æŠ¤

### å®šæœŸç»´æŠ¤ä»»åŠ¡

#### 1. ç³»ç»Ÿæ›´æ–°
```bash
# æ¯æœˆæ‰§è¡Œç³»ç»Ÿæ›´æ–°
sudo apt update && sudo apt upgrade -y

# æ›´æ–° containerdï¼ˆè°¨æ…æ“ä½œï¼‰
sudo apt update && sudo apt install containerd.io
sudo systemctl restart containerd
```

#### 2. å¤‡ä»½å…³é”®é…ç½®
```bash
# å¤‡ä»½ Kubernetes é…ç½®
sudo cp -r /etc/kubernetes /backup/kubernetes-$(date +%Y%m%d)

# å¤‡ä»½ etcd æ•°æ®
sudo ETCDCTL_API=3 etcdctl snapshot save /backup/etcd-snapshot-$(date +%Y%m%d).db \
  --endpoints=https://127.0.0.1:2379 \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/healthcheck-client.crt \
  --key=/etc/kubernetes/pki/etcd/healthcheck-client.key
```

#### 3. æ¸…ç†æ— ç”¨èµ„æº
```bash
# æ¸…ç†æ— ç”¨çš„å®¹å™¨é•œåƒ
sudo ctr images prune

# æ¸…ç†æ— ç”¨çš„ Kubernetes èµ„æº
kubectl delete pods --field-selector=status.phase=Succeeded -A
kubectl delete pods --field-selector=status.phase=Failed -A
```

### ç›‘æ§æŒ‡æ ‡

é‡è¦çš„ç›‘æ§æŒ‡æ ‡åŒ…æ‹¬ï¼š
- èŠ‚ç‚¹ CPUã€å†…å­˜ã€ç£ç›˜ä½¿ç”¨ç‡
- Pod çŠ¶æ€å’Œé‡å¯æ¬¡æ•°
- GPU ä½¿ç”¨ç‡å’Œæ¸©åº¦
- ç½‘ç»œæµé‡å’Œå»¶è¿Ÿ
- å­˜å‚¨ I/O æ€§èƒ½

## å®Œå…¨å¸è½½

å¦‚æœéœ€è¦å®Œå…¨åˆ é™¤ Kubernetes é›†ç¾¤ï¼š

```bash
# é‡ç½® kubeadm
sudo kubeadm reset -f

# åˆ é™¤é…ç½®æ–‡ä»¶
sudo rm -rf /etc/kubernetes
sudo rm -rf ~/.kube

# åˆ é™¤ç½‘ç»œé…ç½®
sudo rm -rf /etc/cni/net.d

# åœæ­¢å’Œç¦ç”¨æœåŠ¡
sudo systemctl stop kubelet containerd
sudo systemctl disable kubelet containerd

# å¸è½½åŒ…
sudo apt remove -y kubeadm kubectl kubelet containerd.io
sudo apt autoremove -y

# åˆ é™¤ä»“åº“é…ç½®
sudo rm -f /etc/apt/sources.list.d/kubernetes.list
sudo rm -f /etc/apt/sources.list.d/docker.list

# åˆ é™¤æ•°æ®ç›®å½•
sudo rm -rf /var/lib/kubelet
sudo rm -rf /var/lib/containerd
sudo rm -rf /opt/cni

# æ¢å¤ç³»ç»Ÿé…ç½®
sudo rm -f /etc/modules-load.d/k8s.conf
sudo rm -f /etc/sysctl.d/k8s.conf
sudo sysctl --system

# é‡å¯ç³»ç»Ÿ
sudo reboot
```

## æ€»ç»“

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»äº†åœ¨ Ubuntu 24.04 ç³»ç»Ÿä¸Šå®‰è£…å•èŠ‚ç‚¹ Kubernetes é›†ç¾¤çš„å®Œæ•´è¿‡ç¨‹ï¼ŒåŒ…æ‹¬ï¼š

1. **åŸºç¡€ç¯å¢ƒå‡†å¤‡**: ç³»ç»Ÿé…ç½®ã€é˜²ç«å¢™ã€å†…æ ¸å‚æ•°
2. **å®¹å™¨è¿è¡Œæ—¶**: containerd å®‰è£…å’Œé…ç½®
3. **Kubernetes æ ¸å¿ƒ**: kubeadmã€kubeletã€kubectl å®‰è£…
4. **é›†ç¾¤åˆå§‹åŒ–**: å•èŠ‚ç‚¹é›†ç¾¤é…ç½®
5. **ç½‘ç»œæ’ä»¶**: Flannel ç½‘ç»œæ–¹æ¡ˆ
6. **å­˜å‚¨ç³»ç»Ÿ**: local-path-provisioner æœ¬åœ°å­˜å‚¨
7. **è´Ÿè½½å‡è¡¡**: NGINX Ingress Controller
8. **ç›‘æ§ç³»ç»Ÿ**: Prometheus + Grafana å®Œæ•´ç›‘æ§
9. **ç®¡ç†ç•Œé¢**: Kubernetes Dashboard
10. **GPU æ”¯æŒ**: NVIDIA GPU Operator é…ç½®

è¯¥é…ç½®æ–¹æ¡ˆå…¼é¡¾äº†åŠŸèƒ½å®Œæ•´æ€§å’Œèµ„æºæ•ˆç‡ï¼Œé€‚åˆå¼€å‘ã€æµ‹è¯•å’Œå°è§„æ¨¡ç”Ÿäº§ç¯å¢ƒä½¿ç”¨ã€‚

## ä¸‹ä¸€æ­¥

é›†ç¾¤å®‰è£…å®Œæˆåï¼Œæ‚¨å¯ä»¥ï¼š
1. éƒ¨ç½²åº”ç”¨ç¨‹åºåˆ°é›†ç¾¤
2. é…ç½® CI/CD æµæ°´çº¿
3. é›†æˆå¤–éƒ¨æœåŠ¡
4. ä¼˜åŒ–æ€§èƒ½å’Œå®‰å…¨é…ç½®
5. æ‰©å±•é›†ç¾¤åŠŸèƒ½

## å‚è€ƒèµ„æ–™

- [Kubernetes å®˜æ–¹æ–‡æ¡£](https://kubernetes.io/docs/)
- [containerd å®˜æ–¹æ–‡æ¡£](https://containerd.io/docs/)
- [Flannel æ–‡æ¡£](https://github.com/flannel-io/flannel)
- [NGINX Ingress Controller](https://kubernetes.github.io/ingress-nginx/)
- [Prometheus Operator](https://prometheus-operator.dev/)
- [NVIDIA GPU Operator](https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/overview.html)

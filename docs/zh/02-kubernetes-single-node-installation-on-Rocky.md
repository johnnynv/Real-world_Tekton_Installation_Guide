# Rocky Linux 10 å•èŠ‚ç‚¹ Kubernetes é›†ç¾¤å®‰è£…æŒ‡å—

æœ¬æŒ‡å—è¯¦ç»†ä»‹ç»å¦‚ä½•åœ¨ Rocky Linux 10 ç³»ç»Ÿä¸Šå®‰è£…å•èŠ‚ç‚¹ Kubernetes é›†ç¾¤ï¼Œæ”¯æŒ GPU å·¥ä½œè´Ÿè½½ã€‚

## ğŸ“‹ æŠ€æœ¯æ–¹æ¡ˆ

- **Kubernetes**: kubeadm v1.31.12
- **å®¹å™¨è¿è¡Œæ—¶**: containerd v1.7.27
- **ç½‘ç»œæ’ä»¶**: Calico v3.29.2
- **å­˜å‚¨**: Local Path Provisioner v0.0.30
- **ç›‘æ§**: Metrics Server + NVIDIA DCGM Exporter
- **ä»ªè¡¨æ¿**: Kubernetes Dashboard v2.7.0
- **GPUæ”¯æŒ**: NVIDIA GPU Operator
- **åŒ…ç®¡ç†**: Helm v3.18.5

## ğŸ æ­¥éª¤1ï¼šç³»ç»Ÿç¯å¢ƒæ£€æŸ¥

```bash
# æ£€æŸ¥æ“ä½œç³»ç»Ÿç‰ˆæœ¬
cat /etc/os-release
# é¢„æœŸè¾“å‡ºï¼šRocky Linux 10.0 (Red Quartz)

# æ£€æŸ¥ç¡¬ä»¶èµ„æº
free -h
nproc
df -h /

# æ£€æŸ¥ç½‘ç»œå’Œä¸»æœºå
hostname
hostname -I

# æ£€æŸ¥é˜²ç«å¢™çŠ¶æ€
systemctl status firewalld
# é¢„æœŸçŠ¶æ€ï¼šinactive (disabled)

# æ£€æŸ¥SELinuxçŠ¶æ€
getenforce
# é¢„æœŸè¾“å‡ºï¼šDisabled

# æ£€æŸ¥swapçŠ¶æ€
swapon --show
free -h
# é¢„æœŸï¼šSwapä¸º0B (å·²å…³é—­)
```

**éªŒè¯ç»“æœ**ï¼š
- âœ… Rocky Linux 10.0 ç³»ç»Ÿ
- âœ… å†…å­˜ 502GBï¼ŒCPU 32æ ¸ï¼Œç£ç›˜ 3TB
- âœ… é˜²ç«å¢™å·²å…³é—­
- âœ… SELinuxå·²ç¦ç”¨
- âœ… Swapå·²å…³é—­

## ğŸ”§ æ­¥éª¤2ï¼šç³»ç»Ÿå‰ç½®é…ç½®

### é…ç½®å†…æ ¸æ¨¡å—

```bash
# é…ç½®éœ€è¦çš„å†…æ ¸æ¨¡å—
cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

# åŠ è½½å†…æ ¸æ¨¡å—
sudo modprobe overlay
sudo modprobe br_netfilter

# éªŒè¯æ¨¡å—åŠ è½½
lsmod | grep -E "(overlay|br_netfilter)"
```

### é…ç½®å†…æ ¸å‚æ•°

```bash
# é…ç½®ç½‘ç»œå‚æ•°
cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF

# åº”ç”¨é…ç½®
sudo sysctl --system

# éªŒè¯å…³é”®å‚æ•°
sysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward
```

**éªŒè¯ç»“æœ**ï¼š
- âœ… overlay å’Œ br_netfilter æ¨¡å—å·²åŠ è½½
- âœ… ç½‘ç»œè½¬å‘å‚æ•°å·²å¯ç”¨

## ğŸ³ æ­¥éª¤3ï¼šå®‰è£…containerdå®¹å™¨è¿è¡Œæ—¶

### æ·»åŠ Dockerä»“åº“

```bash
# æ·»åŠ Dockerä»“åº“ï¼ˆåŒ…å«containerdï¼‰
sudo dnf config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo

# æ›´æ–°ç¼“å­˜
sudo dnf makecache

# æœç´¢containerd
sudo dnf search containerd
```

### å®‰è£…containerd

```bash
# å®‰è£…containerd.io
sudo dnf install -y containerd.io

# ç”Ÿæˆé»˜è®¤é…ç½®
sudo mkdir -p /etc/containerd
sudo containerd config default | sudo tee /etc/containerd/config.toml

# é…ç½®systemd cgroupé©±åŠ¨
sudo sed -i 's/SystemdCgroup = false/SystemdCgroup = true/g' /etc/containerd/config.toml

# éªŒè¯é…ç½®
grep -n "SystemdCgroup" /etc/containerd/config.toml
```

### å¯åŠ¨containerdæœåŠ¡

```bash
# å¯åŠ¨å¹¶å¯ç”¨æœåŠ¡
sudo systemctl enable --now containerd

# éªŒè¯çŠ¶æ€
systemctl status containerd --no-pager
```

**éªŒè¯ç»“æœ**ï¼š
- âœ… containerd v1.7.27 å®‰è£…æˆåŠŸ
- âœ… systemd cgroup é©±åŠ¨å·²é…ç½®
- âœ… æœåŠ¡è¿è¡Œæ­£å¸¸

## âš™ï¸ æ­¥éª¤4ï¼šå®‰è£…Kuberneteså·¥å…·

### æ·»åŠ Kubernetesä»“åº“

```bash
# æ·»åŠ Kuberneteså®˜æ–¹ä»“åº“
cat <<EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://pkgs.k8s.io/core:/stable:/v1.31/rpm/
enabled=1
gpgcheck=1
gpgkey=https://pkgs.k8s.io/core:/stable:/v1.31/rpm/repodata/repomd.xml.key
exclude=kubelet kubeadm kubectl cri-tools kubernetes-cni
EOF
```

### å®‰è£…Kubernetesç»„ä»¶

```bash
# æ›´æ–°ä»“åº“ç¼“å­˜
sudo dnf makecache

# å®‰è£…kubeadmã€kubeletã€kubectl
sudo dnf install -y kubelet kubeadm kubectl --disableexcludes=kubernetes

# å¯ç”¨kubeletæœåŠ¡
sudo systemctl enable kubelet

# éªŒè¯ç‰ˆæœ¬
kubeadm version
kubelet --version
kubectl version --client
```

**éªŒè¯ç»“æœ**ï¼š
- âœ… kubeadm v1.31.12
- âœ… kubelet v1.31.12
- âœ… kubectl v1.31.12

## ğŸ¯ æ­¥éª¤5ï¼šåˆå§‹åŒ–Kubernetesé›†ç¾¤

### é›†ç¾¤åˆå§‹åŒ–

```bash
# åˆå§‹åŒ–é›†ç¾¤
sudo kubeadm init --pod-network-cidr=192.168.0.0/16 --cri-socket=unix:///var/run/containerd/containerd.sock

# é…ç½®kubectl
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

# ç§»é™¤masterèŠ‚ç‚¹æ±¡ç‚¹ï¼ˆå•èŠ‚ç‚¹é›†ç¾¤ï¼‰
kubectl taint nodes --all node-role.kubernetes.io/control-plane-

# éªŒè¯é›†ç¾¤çŠ¶æ€
kubectl get nodes
kubectl get pods -A
```

**éªŒè¯ç»“æœ**ï¼š
- âœ… é›†ç¾¤åˆå§‹åŒ–æˆåŠŸ
- âœ… èŠ‚ç‚¹çŠ¶æ€ä¸º NotReadyï¼ˆéœ€è¦ç½‘ç»œæ’ä»¶ï¼‰
- âœ… æ§åˆ¶å¹³é¢ç»„ä»¶è¿è¡Œæ­£å¸¸

## ğŸŒ æ­¥éª¤6ï¼šå®‰è£…Calicoç½‘ç»œæ’ä»¶

### å®‰è£…Tigera Operator

```bash
# å®‰è£…Calico operator
kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.29.2/manifests/tigera-operator.yaml
```

### é…ç½®Calicoå®‰è£…

```bash
# åˆ›å»ºCalicoå®‰è£…é…ç½®
cat <<EOF | kubectl create -f -
apiVersion: operator.tigera.io/v1
kind: Installation
metadata:
  name: default
spec:
  calicoNetwork:
    ipPools:
    - blockSize: 26
      cidr: 192.168.0.0/16
      encapsulation: VXLANCrossSubnet
      natOutgoing: Enabled
      nodeSelector: all()
EOF

# ç­‰å¾…å®‰è£…å®Œæˆ
kubectl wait --for=condition=Ready --timeout=300s installation/default

# éªŒè¯å®‰è£…
kubectl get pods -n calico-system
kubectl get nodes
```

**éªŒè¯ç»“æœ**ï¼š
- âœ… Calicoç½‘ç»œæ’ä»¶å®‰è£…æˆåŠŸ
- âœ… èŠ‚ç‚¹çŠ¶æ€å˜ä¸º Ready
- âœ… ç½‘ç»œè¿é€šæ€§æ­£å¸¸

## ğŸ’¾ æ­¥éª¤7ï¼šå®‰è£…Local Path Provisionerå­˜å‚¨

### å®‰è£…å­˜å‚¨provisioner

```bash
# å®‰è£…Local Path Provisioner
kubectl apply -f https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.30/deploy/local-path-storage.yaml

# è®¾ç½®ä¸ºé»˜è®¤å­˜å‚¨ç±»
kubectl patch storageclass local-path -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'

# éªŒè¯å®‰è£…
kubectl get storageclass
kubectl get pods -n local-path-storage
```

**éªŒè¯ç»“æœ**ï¼š
- âœ… local-path è®¾ä¸ºé»˜è®¤å­˜å‚¨ç±»
- âœ… provisioner è¿è¡Œæ­£å¸¸

## ğŸ“Š æ­¥éª¤8ï¼šå®‰è£…Metrics Serverç›‘æ§

### å®‰è£…Metrics Server

```bash
# å®‰è£…Metrics Server
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

# ä¿®å¤å•èŠ‚ç‚¹é›†ç¾¤TLSé—®é¢˜
kubectl patch deployment metrics-server -n kube-system --patch='
spec:
  template:
    spec:
      containers:
      - name: metrics-server
        args:
        - --cert-dir=/tmp
        - --secure-port=10250
        - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
        - --kubelet-use-node-status-port
        - --metric-resolution=15s
        - --kubelet-insecure-tls
'

# éªŒè¯åŠŸèƒ½
kubectl get pods -n kube-system -l k8s-app=metrics-server
kubectl top nodes
```

**éªŒè¯ç»“æœ**ï¼š
- âœ… Metrics Serverè¿è¡Œæ­£å¸¸
- âœ… èƒ½å¤Ÿè·å–èŠ‚ç‚¹èµ„æºæŒ‡æ ‡

## ğŸ–¥ï¸ æ­¥éª¤9ï¼šå®‰è£…Kubernetes Dashboard

### å®‰è£…Dashboard

```bash
# å®‰è£…Dashboard
kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml

# åˆ›å»ºç®¡ç†å‘˜ç”¨æˆ·
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: ServiceAccount
metadata:
  name: admin-user
  namespace: kubernetes-dashboard
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: admin-user
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: admin-user
  namespace: kubernetes-dashboard
EOF

# éªŒè¯å®‰è£…
kubectl get pods -n kubernetes-dashboard
```

### è®¿é—®Dashboard

```bash
# è·å–è®¿é—®Token
kubectl -n kubernetes-dashboard create token admin-user

# å¯åŠ¨ç«¯å£è½¬å‘
kubectl port-forward -n kubernetes-dashboard service/kubernetes-dashboard 8443:443
```

**è®¿é—®ä¿¡æ¯**ï¼š
- **URL**: https://localhost:8443
- **Token**: é€šè¿‡ä¸Šè¿°å‘½ä»¤è·å–
- **ç”¨æˆ·**: admin-user

## ğŸ“¦ æ­¥éª¤10ï¼šå®‰è£…HelmåŒ…ç®¡ç†å™¨

```bash
# å®‰è£…Helm
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

# éªŒè¯ç‰ˆæœ¬
helm version
```

**éªŒè¯ç»“æœ**ï¼š
- âœ… Helm v3.18.5 å®‰è£…æˆåŠŸ

## ğŸ® æ­¥éª¤11ï¼šå®‰è£…NVIDIA GPU Operator

### æ·»åŠ NVIDIA Helmä»“åº“

```bash
# æ·»åŠ NVIDIAä»“åº“
helm repo add nvidia https://helm.ngc.nvidia.com/nvidia
helm repo update
```

### å®‰è£…GPU Operator

```bash
# å®‰è£…GPU Operatorï¼ˆç¦ç”¨é©±åŠ¨å®‰è£…ï¼‰
helm install --wait gpu-operator nvidia/gpu-operator \
  --namespace gpu-operator \
  --create-namespace \
  --set driver.enabled=false

# éªŒè¯å®‰è£…
kubectl get pods -n gpu-operator
```

### éªŒè¯GPUèµ„æº

```bash
# æ£€æŸ¥GPUèµ„æº
kubectl describe node | grep -A 5 -B 5 nvidia.com/gpu

# æ£€æŸ¥GPUåˆ†é…
kubectl get nodes -o=custom-columns=NAME:.metadata.name,GPU:.status.allocatable.nvidia\\.com/gpu
```

**éªŒè¯ç»“æœ**ï¼š
- âœ… è¯†åˆ«åˆ°4ä¸ªGPUè®¾å¤‡
- âœ… GPU Operatoræ‰€æœ‰ç»„ä»¶è¿è¡Œæ­£å¸¸
- âœ… NVIDIA DCGM Exporterè‡ªåŠ¨å®‰è£…

## ğŸ“ˆ æ­¥éª¤12ï¼šéªŒè¯DCGMç›‘æ§æŒ‡æ ‡

### è®¿é—®GPUæŒ‡æ ‡

```bash
# ç«¯å£è½¬å‘DCGM Exporter
kubectl port-forward -n gpu-operator service/nvidia-dcgm-exporter 9400:9400 &

# æµ‹è¯•æŒ‡æ ‡è·å–
curl -s http://localhost:9400/metrics | grep -E "(DCGM_FI_DEV_GPU_UTIL|DCGM_FI_DEV_MEM_COPY_UTIL)" | head -5
```

**DCGMæŒ‡æ ‡è®¿é—®**ï¼š
- **URL**: http://localhost:9400/metrics
- **ä¸»è¦æŒ‡æ ‡**: GPUåˆ©ç”¨ç‡ã€å†…å­˜ä½¿ç”¨ã€æ¸©åº¦ç­‰

## âœ… æ­¥éª¤13ï¼šå®Œæ•´ç³»ç»ŸéªŒè¯

### é›†ç¾¤çŠ¶æ€éªŒè¯

```bash
echo "ğŸ” å®Œæ•´ç³»ç»ŸéªŒè¯"
echo "========================="

# 1. èŠ‚ç‚¹çŠ¶æ€
echo "1. èŠ‚ç‚¹çŠ¶æ€ï¼š"
kubectl get nodes

# 2. æ‰€æœ‰PodçŠ¶æ€
echo "2. å…³é”®PodçŠ¶æ€ï¼š"
kubectl get pods -A --field-selector=status.phase!=Succeeded | grep -v Completed

# 3. GPUèµ„æº
echo "3. GPUèµ„æºåˆ†é…ï¼š"
kubectl get nodes -o=custom-columns=NAME:.metadata.name,GPU:.status.allocatable.nvidia\\.com/gpu

# 4. å­˜å‚¨ç±»
echo "4. å­˜å‚¨ç±»ï¼š"
kubectl get storageclass

# 5. ç½‘ç»œæ’ä»¶
echo "5. ç½‘ç»œæ’ä»¶ï¼š"
kubectl get pods -n calico-system

echo "========================="
echo "ğŸ‰ ç³»ç»ŸéªŒè¯å®Œæˆï¼"
```

## ğŸš€ è®¿é—®ä¿¡æ¯æ±‡æ€»

### Dashboardå’Œç›‘æ§è®¿é—®

#### ğŸŒ **é€šè¿‡nip.ioåŸŸåè®¿é—®ï¼ˆæ¨èï¼‰**

##### Dashboardè®¿é—®
```bash
# åˆ›å»ºNodePortæœåŠ¡
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Service
metadata:
  name: kubernetes-dashboard-nodeport
  namespace: kubernetes-dashboard
  labels:
    k8s-app: kubernetes-dashboard
spec:
  type: NodePort
  ports:
  - port: 443
    targetPort: 8443
    nodePort: 30443
    protocol: TCP
    name: https
  selector:
    k8s-app: kubernetes-dashboard
EOF

# å®‰è£…nginxåå‘ä»£ç†
sudo dnf install -y nginx

# åˆ›å»ºSSLè¯ä¹¦
sudo mkdir -p /etc/nginx/ssl
sudo openssl req -x509 -nodes -days 365 -newkey rsa:2048 \
  -keyout /etc/nginx/ssl/dashboard.key \
  -out /etc/nginx/ssl/dashboard.crt \
  -subj "/C=CN/ST=State/L=City/O=Organization/CN=dashboard.$(hostname -I | awk '{print $1}').nip.io"

# é…ç½®nginx
sudo bash -c 'cat > /etc/nginx/conf.d/kubernetes-dashboard.conf << "EOF"
server {
    listen 443 ssl;
    server_name dashboard.$(hostname -I | awk "{print $1}").nip.io;

    ssl_certificate /etc/nginx/ssl/dashboard.crt;
    ssl_certificate_key /etc/nginx/ssl/dashboard.key;
    ssl_protocols TLSv1.2 TLSv1.3;

    location / {
        proxy_pass https://127.0.0.1:30443;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_ssl_verify off;
    }
}

server {
    listen 80;
    server_name dashboard.$(hostname -I | awk "{print $1}").nip.io;
    return 301 https://$server_name$request_uri;
}

# GPUç›‘æ§æœåŠ¡
server {
    listen 80;
    server_name gpu-metrics.$(hostname -I | awk "{print $1}").nip.io;

    location / {
        proxy_pass http://127.0.0.1:30400;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
EOF'

# å¯åŠ¨nginx
sudo systemctl enable --now nginx

# è·å–è®¿é—®Token
kubectl -n kubernetes-dashboard create token admin-user
```

##### GPUç›‘æ§è®¿é—®
```bash
# åˆ›å»ºDCGM Exporter NodePortæœåŠ¡
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Service
metadata:
  name: nvidia-dcgm-exporter-nodeport
  namespace: gpu-operator
  labels:
    app: nvidia-dcgm-exporter
spec:
  type: NodePort
  ports:
  - port: 9400
    targetPort: 9400
    nodePort: 30400
    protocol: TCP
    name: metrics
  selector:
    app: nvidia-dcgm-exporter
EOF
```

#### ğŸ“± **è®¿é—®é“¾æ¥**

- **Kubernetes Dashboard**: https://dashboard.10.78.14.61.nip.io
- **GPUç›‘æ§æŒ‡æ ‡**: http://gpu-metrics.10.78.14.61.nip.io/metrics  
- **Tokenè·å–**: `kubectl -n kubernetes-dashboard create token admin-user`

#### ğŸ”§ **æœ¬åœ°ç«¯å£è½¬å‘è®¿é—®ï¼ˆå¤‡é€‰ï¼‰**
```bash
# Dashboardç«¯å£è½¬å‘
kubectl port-forward -n kubernetes-dashboard service/kubernetes-dashboard 8443:443 &

# GPUç›‘æ§ç«¯å£è½¬å‘  
kubectl port-forward -n gpu-operator service/nvidia-dcgm-exporter 9400:9400 &
```

- **Dashboard URL**: https://localhost:8443
- **DCGMæŒ‡æ ‡URL**: http://localhost:9400/metrics

## ğŸ“‹ å®‰è£…ç»“æœæ‘˜è¦

### âœ… æˆåŠŸå®‰è£…çš„ç»„ä»¶
1. **Kubernetesé›†ç¾¤**: v1.31.12 å•èŠ‚ç‚¹é›†ç¾¤
2. **å®¹å™¨è¿è¡Œæ—¶**: containerd v1.7.27
3. **ç½‘ç»œæ’ä»¶**: Calico v3.29.2
4. **å­˜å‚¨**: Local Path Provisionerï¼ˆé»˜è®¤å­˜å‚¨ç±»ï¼‰
5. **ç›‘æ§**: Metrics Server + NVIDIA DCGM Exporter
6. **ä»ªè¡¨æ¿**: Kubernetes Dashboard v2.7.0
7. **GPUæ”¯æŒ**: NVIDIA GPU Operator
8. **åŒ…ç®¡ç†**: Helm v3.18.5

### ğŸ“Š é›†ç¾¤è§„æ ¼
- **èŠ‚ç‚¹æ•°é‡**: 1ä¸ªï¼ˆcontrol-plane + workerï¼‰
- **GPUè®¾å¤‡**: 4x NVIDIA Graphics Device
- **æ€»æ˜¾å­˜**: 716GBï¼ˆ4x179GBï¼‰
- **è®¡ç®—èƒ½åŠ›**: 10.0ï¼ˆæ”¯æŒæœ€æ–°CUDAç‰¹æ€§ï¼‰
- **ç½‘ç»œ**: Calico VXLANï¼ŒPod CIDR 192.168.0.0/16
- **å­˜å‚¨**: æœ¬åœ°è·¯å¾„å­˜å‚¨ï¼Œæ”¯æŒåŠ¨æ€åˆ†é…

### ğŸ¯ åç»­é›†æˆå‡†å¤‡
è¯¥é›†ç¾¤å·²ä¸ºä»¥ä¸‹å·¥ä½œè´Ÿè½½åšå¥½å‡†å¤‡ï¼š
- **Tekton Pipeline**: GPUåŠ é€Ÿçš„CI/CDå·¥ä½œæµ
- **ç§‘å­¦è®¡ç®—**: PyTorchã€TensorFlowã€RAPIDSç­‰
- **æœºå™¨å­¦ä¹ **: æ¨¡å‹è®­ç»ƒå’Œæ¨ç†å·¥ä½œè´Ÿè½½
- **å®¹å™¨åŒ–åº”ç”¨**: æ”¯æŒGPUçš„å®¹å™¨åº”ç”¨

## ğŸ› ï¸ ä¸€é”®å®‰è£…è„šæœ¬

### å¿«é€Ÿå®‰è£…
```bash
# ä¸‹è½½å¹¶è¿è¡Œå®‰è£…è„šæœ¬
curl -O https://raw.githubusercontent.com/your-repo/scripts/install-k8s-gpu.sh
chmod +x install-k8s-gpu.sh
./install-k8s-gpu.sh
```

### å®Œæ•´å¸è½½
```bash
# ä¸‹è½½å¹¶è¿è¡Œå¸è½½è„šæœ¬
curl -O https://raw.githubusercontent.com/your-repo/scripts/uninstall-k8s-gpu.sh
chmod +x uninstall-k8s-gpu.sh
./uninstall-k8s-gpu.sh
```

## ğŸ“š ä¸‹ä¸€æ­¥

é›†ç¾¤å®‰è£…å®Œæˆåï¼Œæ‚¨å¯ä»¥ç»§ç»­ï¼š
1. [Tekton æ ¸å¿ƒç»„ä»¶å®‰è£…](04-tekton-installation.md)
2. [Tekton Triggers é…ç½®](05-tekton-triggers-setup.md)
3. [GPU Pipeline éƒ¨ç½²](07-gpu-pipeline-deployment.md)

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜
1. **èŠ‚ç‚¹NotReady**: æ£€æŸ¥ç½‘ç»œæ’ä»¶å®‰è£…çŠ¶æ€
2. **Podæ‹‰å–é•œåƒå¤±è´¥**: æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒDNSé…ç½®
3. **GPUèµ„æºæœªè¯†åˆ«**: éªŒè¯GPU Operatorå’Œé©±åŠ¨çŠ¶æ€
4. **Dashboardæ— æ³•è®¿é—®**: æ£€æŸ¥ç«¯å£è½¬å‘å’ŒTokenæœ‰æ•ˆæ€§

### è¯Šæ–­å‘½ä»¤
```bash
# èŠ‚ç‚¹è¯Šæ–­
kubectl describe nodes

# Podè¯Šæ–­
kubectl get pods -A
kubectl describe pod <pod-name> -n <namespace>

# GPUè¯Šæ–­
kubectl get pods -n gpu-operator
kubectl logs -n gpu-operator <gpu-operator-pod>

# ç½‘ç»œè¯Šæ–­
kubectl get pods -n calico-system
kubectl logs -n calico-system <calico-pod>
```

## ğŸ“– å‚è€ƒèµ„æ–™

- [Kuberneteså®˜æ–¹æ–‡æ¡£](https://kubernetes.io/docs/)
- [Calicoç½‘ç»œæ’ä»¶](https://docs.tigera.io/calico/)
- [NVIDIA GPU Operator](https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/)
- [Local Path Provisioner](https://github.com/rancher/local-path-provisioner)
- [Kubernetes Dashboard](https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/)

apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: gpu-papermill-production-init-simple
  namespace: tekton-pipelines
  labels:
    app.kubernetes.io/name: gpu-papermill-production-init-simple
    app.kubernetes.io/component: tekton-task
    task.tekton.dev/gpu: "true"
spec:
  description: |
    Simplified production-grade Tekton Task with Init Container pattern.
    Tests RMM issue resolution with enhanced GPU environment variables.
  
  workspaces:
  - name: shared-storage
    description: Workspace for notebook files and outputs
    mountPath: /workspace/shared
  
  params:
  - name: notebook-relative-dir
    description: Directory containing the notebook
    type: string
    default: "notebooks"
  - name: notebook-filename
    description: Name of the notebook file
    type: string
    default: "01_scRNA_analysis_preprocessing.ipynb"
  - name: output-notebook
    description: Name of the output notebook file
    type: string
    default: "01_scRNA_analysis_preprocessing_output.ipynb"
  - name: container-image
    description: Container image to use
    type: string
    default: "nvcr.io/nvidia/rapidsai/notebooks:25.04-cuda12.8-py3.12"
  
  volumes:
  - name: conda-writable
    emptyDir: {}
  - name: dev-shm
    emptyDir:
      medium: Memory
      sizeLimit: 64Gi
  
  stepTemplate:
    env:
    - name: NVIDIA_VISIBLE_DEVICES
      value: "all"
    - name: NVIDIA_DRIVER_CAPABILITIES
      value: "compute,utility"
  
  steps:
  # Init Container - Permission Setup
  - name: init-permission-setup
    image: $(params.container-image)
    securityContext:
      runAsUser: 0
      runAsGroup: 0
      allowPrivilegeEscalation: true
    volumeMounts:
    - name: conda-writable
      mountPath: /opt/conda-writable
    - name: dev-shm
      mountPath: /dev/shm
    script: |
      #!/bin/bash
      set -eu
      
      echo "🔧 PRODUCTION INIT CONTAINER - PERMISSION SETUP"
      
      # Set up rapids user (UID 1001)
      RAPIDS_UID=1001
      RAPIDS_GID=1001
      
      if ! id rapids >/dev/null 2>&1; then
        groupadd -g $RAPIDS_GID rapids || echo "Group exists"
        useradd -u $RAPIDS_UID -g $RAPIDS_GID -m -s /bin/bash rapids || echo "User exists"
      fi
      
      mkdir -p /home/rapids
      chown $RAPIDS_UID:$RAPIDS_GID /home/rapids
      
      # Set up conda permissions
      mkdir -p /opt/conda-writable
      cp -r /opt/conda/* /opt/conda-writable/ 2>/dev/null || echo "Conda copy done"
      chown -R $RAPIDS_UID:$RAPIDS_GID /opt/conda-writable/
      chmod -R 755 /opt/conda-writable/
      
      # Set up workspace permissions
      chown -R $RAPIDS_UID:$RAPIDS_GID $(workspaces.shared-storage.path)/
      chmod -R 755 $(workspaces.shared-storage.path)/
      
      # Create artifacts directory
      mkdir -p $(workspaces.shared-storage.path)/artifacts
      chown $RAPIDS_UID:$RAPIDS_GID $(workspaces.shared-storage.path)/artifacts
      
      # Set shared memory permissions
      chown -R $RAPIDS_UID:$RAPIDS_GID /dev/shm
      chmod -R 777 /dev/shm
      
      echo "init-status:success" > $(workspaces.shared-storage.path)/init-status
      echo "✅ Permission setup completed"
  
  # Main Container - Rapids User Execution
  - name: execute-notebook-with-rmm-test
    image: $(params.container-image)
    securityContext:
      runAsUser: 1001  # rapids user
      runAsGroup: 1001 # rapids group
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      seccompProfile:
        type: RuntimeDefault
    env:
    - name: HOME
      value: "/home/rapids"
    - name: USER
      value: "rapids"
    - name: PATH
      value: "/home/rapids/.local/bin:/opt/conda-writable/bin:/usr/local/bin:/usr/bin:/bin"
    - name: CONDA_DEFAULT_ENV
      value: "base"
    - name: PYTHONPATH
      value: "/opt/conda-writable/lib/python3.12/site-packages"
    # Critical GPU environment variables for Jupyter kernel
    - name: CUDA_VISIBLE_DEVICES
      value: "0,1,2,3"
    - name: LD_LIBRARY_PATH
      value: "/usr/local/cuda/lib64:/opt/conda-writable/lib"
    - name: CUDA_HOME
      value: "/usr/local/cuda"
    volumeMounts:
    - name: conda-writable
      mountPath: /opt/conda
    - name: dev-shm
      mountPath: /dev/shm
    script: |
      #!/bin/bash
      set -eu
      
      echo "🚀 PRODUCTION MAIN CONTAINER - RAPIDS USER EXECUTION"
      echo "Running as: $(id)"
      echo "Home: $HOME"
      
      # Check init status
      if [ -f "$(workspaces.shared-storage.path)/init-status" ]; then
        echo "✅ Init container completed successfully"
      else
        echo "❌ Init container failed"
        exit 1
      fi
      
      # GPU verification
      echo "🔍 GPU Environment Check:"
      echo "CUDA_VISIBLE_DEVICES: $CUDA_VISIBLE_DEVICES"
      echo "LD_LIBRARY_PATH: $LD_LIBRARY_PATH"
      nvidia-smi --query-gpu=name,memory.total --format=csv,noheader || echo "nvidia-smi warning"
      
      # Check notebook
      NOTEBOOK_PATH="$(workspaces.shared-storage.path)/$(params.notebook-relative-dir)/$(params.notebook-filename)"
      if [ ! -f "$NOTEBOOK_PATH" ]; then
        echo "❌ Notebook not found: $NOTEBOOK_PATH"
        exit 1
      fi
      echo "✅ Notebook found"
      
      # Python setup
      PYTHON_BIN="/opt/conda/bin/python"
      echo "🐍 Python setup:"
      $PYTHON_BIN --version
      
      # Critical GPU test in Python
      echo "🔍 Testing GPU in Python:"
      $PYTHON_BIN -c 'import cupy as cp; print("GPU count:", cp.cuda.runtime.getDeviceCount())' || echo "⚠️ GPU test failed"
      
      # Install packages
      echo "📦 Installing packages..."
      $PYTHON_BIN -m pip install --user --quiet scanpy papermill jupyter nbconvert
      
      # Execute notebook
      OUTPUT_NOTEBOOK="$(workspaces.shared-storage.path)/artifacts/$(params.output-notebook)"
      echo "🔥 Executing notebook with enhanced GPU environment..."
      
      if /home/rapids/.local/bin/papermill \
        "$NOTEBOOK_PATH" \
        "$OUTPUT_NOTEBOOK" \
        --log-output \
        --log-level DEBUG \
        --progress-bar \
        --report-mode \
        --kernel python3 2>&1 | tee $(workspaces.shared-storage.path)/artifacts/papermill.log; then
        
        echo "✅ Papermill execution completed"
        
        if [ -f "$OUTPUT_NOTEBOOK" ]; then
          SIZE=$(du -h "$OUTPUT_NOTEBOOK" | cut -f1)
          echo "✅ Output notebook created: $SIZE"
          
          # Check for specific errors
          if grep -q "AttributeError.*CUDARuntimeError.*no attribute.*msg" "$OUTPUT_NOTEBOOK" 2>/dev/null; then
            echo "❌ RMM AttributeError still present"
            echo "📊 RESULT: RMM issue NOT resolved"
          elif grep -q "cudaErrorNoDevice\|no CUDA-capable device" "$OUTPUT_NOTEBOOK" 2>/dev/null; then
            echo "❌ GPU context issue detected"
            echo "📊 RESULT: GPU context issue NOT resolved"
          elif grep -q "ModuleNotFoundError.*scanpy" "$OUTPUT_NOTEBOOK" 2>/dev/null; then
            echo "❌ Missing dependencies"
            echo "📊 RESULT: Dependency issue"
          else
            echo "✅ No critical errors detected"
            echo "📊 RESULT: RMM issue appears RESOLVED"
          fi
        else
          echo "❌ Output notebook not created"
          echo "📊 RESULT: Execution failed"
        fi
      else
        echo "❌ Papermill execution failed"
        echo "📊 RESULT: Execution failed"
      fi
      
      echo ""
      echo "🎯 RMM RESOLUTION TEST COMPLETED"
      echo "✅ Init Container pattern working"
      echo "✅ RAPIDS user (UID 1001) working"
      echo "✅ Enhanced GPU environment variables applied" 
# Tekton GPU Pipeline éƒ¨ç½²æ•…éšœæ’é™¤

æœ¬æ–‡æ¡£è®°å½•åœ¨éƒ¨ç½²è¿‡ç¨‹ä¸­å‘ç°çš„é—®é¢˜åŠè§£å†³æ–¹æ¡ˆã€‚

## ğŸ“‹ å¸¸è§é—®é¢˜

### 1. kubectl å‘½ä»¤é—®é¢˜

#### é—®é¢˜ï¼š`kubectl version --short` ä¸è¢«æ”¯æŒ
**é”™è¯¯ä¿¡æ¯**ï¼š
```
error: unknown flag: --short
See 'kubectl version --help' for usage.
```

**åŸå› **ï¼šæ–°ç‰ˆæœ¬ kubectl å·²ç§»é™¤ `--short` å‚æ•°

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# é”™è¯¯å‘½ä»¤
kubectl version --short

# æ­£ç¡®å‘½ä»¤
kubectl version
```

**çŠ¶æ€**ï¼šå·²ä¿®å¤æ–‡æ¡£

---

### 2. Git Clone å®‰å…¨å¤„ç†é—®é¢˜

#### é—®é¢˜ï¼šé‡å¤è¿è¡Œpipelineæ—¶git cloneå¤±è´¥
**é”™è¯¯ä¿¡æ¯**ï¼š
```
fatal: destination path 'source' already exists and is not an empty directory.
```

**åŸå› **ï¼šPipelineé‡å¤è¿è¡Œæ—¶ï¼Œworkspaceä¸­å­˜åœ¨ä¹‹å‰è¿è¡Œçš„æ®‹ç•™æ–‡ä»¶

**è§£å†³æ–¹æ¡ˆ**ï¼šè‡ªåŠ¨å¤‡ä»½å’Œå®‰å…¨å¤„ç†æœºåˆ¶

æˆ‘ä»¬çš„å®‰å…¨git cloneå®ç°åŒ…å«ä»¥ä¸‹ç‰¹æ€§ï¼š
- **è‡ªåŠ¨ç›®å½•å¤‡ä»½**ï¼šæ£€æµ‹åˆ°å·²å­˜åœ¨ç›®å½•æ—¶ï¼Œè‡ªåŠ¨åˆ›å»ºæ—¶é—´æˆ³å¤‡ä»½
- **é‡è¯•æœºåˆ¶**ï¼šcloneå¤±è´¥æ—¶è‡ªåŠ¨é‡è¯•ï¼ˆæœ€å¤š3æ¬¡ï¼‰
- **å›æ»šèƒ½åŠ›**ï¼šå¤±è´¥æ—¶å¯è‡ªåŠ¨æ¢å¤å¤‡ä»½
- **è¯¦ç»†æ—¥å¿—**ï¼šåŒ…å«æ—¶é—´æˆ³çš„è¯¦ç»†æ“ä½œæ—¥å¿—

**å®‰å…¨å¤„ç†æµç¨‹**ï¼š
```bash
# 1. æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
if [ -d "${TARGET_DIR}" ]; then
  # 2. åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„å¤‡ä»½
  TIMESTAMP=$(date '+%Y%m%d_%H%M%S')
  BACKUP_DIR="${TARGET_DIR}_backup_${TIMESTAMP}"
  mv "${TARGET_DIR}" "${BACKUP_DIR}"
fi

# 3. æ‰§è¡Œgit cloneï¼ˆå¸¦é‡è¯•ï¼‰
for attempt in $(seq 1 ${MAX_RETRIES}); do
  if git clone "${REPO_URL}" "${TARGET_DIR}"; then
    break
  fi
  # æ¸…ç†å¤±è´¥çš„éƒ¨åˆ†clone
  rm -rf "${TARGET_DIR}"
  sleep $((attempt * 5))  # æŒ‡æ•°é€€é¿
done
```

**å·²æ›´æ–°çš„Taskç»„ä»¶**ï¼š
1. **gpu-env-preparation-task-fixed.yaml** - æ·»åŠ è‡ªåŠ¨å¤‡ä»½æœºåˆ¶
2. **pytest-execution-task.yaml** - æµ‹è¯•ä»“åº“cloneçš„å®‰å…¨å¤„ç†  
3. **safe-git-clone-task.yaml**ï¼ˆæ–°å¢ï¼‰- ç‹¬ç«‹çš„å®‰å…¨git clone task

**æ¸…ç†å¤‡ä»½ç›®å½•**ï¼š
```bash
# æ¸…ç†7å¤©å‰çš„å¤‡ä»½
find /workspace -name "*_backup_*" -type d -mtime +7 -exec rm -rf {} +
```

**çŠ¶æ€**ï¼šå·²ä¿®å¤å¹¶å¢å¼ºå®‰å…¨æªæ–½

---

### 3. ç¯å¢ƒæ¸…ç†é—®é¢˜

#### é—®é¢˜ï¼šç°æœ‰ Tekton ç»„ä»¶å¯¼è‡´éƒ¨ç½²å†²çª
**ç—‡çŠ¶**ï¼š
- å®‰è£…è¿‡ç¨‹ä¸­èµ„æºå·²å­˜åœ¨é”™è¯¯
- EventListener å¤„äº CrashLoopBackOff çŠ¶æ€
- æ— æ³•åˆ›å»ºæ–°çš„ Pipeline èµ„æº

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# æ‰§è¡Œå®Œæ•´ç¯å¢ƒæ¸…ç†
chmod +x scripts/cleanup/clean-tekton-environment.sh
./scripts/cleanup/clean-tekton-environment.sh
```

**éªŒè¯æ¸…ç†å®Œæˆ**ï¼š
```bash
# åº”è¯¥æ²¡æœ‰è¾“å‡º
kubectl get namespaces | grep tekton
kubectl get pods --all-namespaces | grep tekton
```

---

### 4. Tekton API ç‰ˆæœ¬é—®é¢˜

#### é—®é¢˜ï¼šTask å®šä¹‰ä¸­çš„ resources å­—æ®µä½ç½®é”™è¯¯
**é”™è¯¯ä¿¡æ¯**ï¼š
```
error when creating: Task in version "v1" cannot be handled as a Task: strict decoding error: unknown field "spec.steps[0].resources"
```

**åŸå› **ï¼šTekton v1 API ä¸­èµ„æºå®šä¹‰åº”ä½¿ç”¨ `computeResources`

**è§£å†³æ–¹æ¡ˆ**ï¼š
```yaml
# é”™è¯¯é…ç½®
spec:
  steps:
  - name: step
    resources:
      limits:
        nvidia.com/gpu: "1"

# æ­£ç¡®é…ç½®
spec:
  steps:
  - name: step
    computeResources:
      limits:
        nvidia.com/gpu: "1"
```

---

### 5. åŠ¨æ€å‚æ•°é—®é¢˜

#### é—®é¢˜ï¼šèµ„æºé‡å¿…é¡»åŒ¹é…æ­£åˆ™è¡¨è¾¾å¼
**é”™è¯¯ä¿¡æ¯**ï¼š
```
quantities must match the regular expression '^([+-]?[0-9.]+)([eEinumkKMGTP]*[-+]?[0-9]*)$'
```

**åŸå› **ï¼šTekton ä¸æ¥å—åŠ¨æ€å‚æ•°ä½œä¸ºèµ„æºé‡å€¼

**è§£å†³æ–¹æ¡ˆ**ï¼š
```yaml
# é”™è¯¯é…ç½®
computeResources:
  limits:
    nvidia.com/gpu: $(params.gpu-count)

# æ­£ç¡®é…ç½®  
computeResources:
  limits:
    nvidia.com/gpu: "1"
```

---

### 6. YAML æ ¼å¼é—®é¢˜

#### é—®é¢˜ï¼šå¤æ‚çš„å¤šè¡Œè„šæœ¬å¯¼è‡´ YAML è§£æé”™è¯¯
**é”™è¯¯ä¿¡æ¯**ï¼š
```
error converting YAML to JSON: yaml: line X: could not find expected ':'
```

**åŸå› **ï¼šPython è„šæœ¬å—ç¼©è¿›é—®é¢˜

**è§£å†³æ–¹æ¡ˆ**ï¼š
ç®€åŒ–å¤æ‚çš„ Python è„šæœ¬ï¼Œä½¿ç”¨æ›´ç®€å•çš„ shell å‘½ä»¤ï¼š

```yaml
# å¤æ‚çš„ Python è„šæœ¬ï¼ˆå®¹æ˜“å‡ºé”™ï¼‰
script: |
  python3 << 'EOF'
  import json
  # å¤æ‚é€»è¾‘
  EOF

# ç®€åŒ–çš„ shell å‘½ä»¤ï¼ˆæ¨èï¼‰
script: |
  #!/bin/bash
  echo "ç®€å•éªŒè¯"
  grep -q "pattern" file || echo "Not found"
```

---

### 7. Dashboard è®¿é—®é—®é¢˜

#### é—®é¢˜ï¼šDashboard ç™»å½•æˆåŠŸä½†å†…å®¹ä¸€ç›´ loading
**ç—‡çŠ¶**ï¼š
- å¯ä»¥è¾“å…¥ç”¨æˆ·åå¯†ç ç™»å½•
- ç™»å½•åé¡µé¢ç©ºç™½æˆ–ä¸€ç›´æ˜¾ç¤ºloading
- æ— æ³•æ˜¾ç¤ºPipelineã€Taskç­‰å†…å®¹

**é”™è¯¯æ—¥å¿—**ï¼š
```
dial tcp 10.96.0.1:443: i/o timeout
Error getting the Tekton dashboard info ConfigMap
```

**åŸå› **ï¼šç½‘ç»œç­–ç•¥è¿‡äºä¸¥æ ¼ï¼Œé˜»æ­¢äº†Dashboardè®¿é—®Kubernetes APIæœåŠ¡å™¨

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# æ–¹æ¡ˆ1ï¼šé‡å¯Dashboard Podï¼ˆä¸´æ—¶ï¼‰
kubectl delete pod -l app.kubernetes.io/name=dashboard -n tekton-pipelines

# æ–¹æ¡ˆ2ï¼šä¿®æ­£ç½‘ç»œç­–ç•¥ï¼ˆæ¨èï¼‰
# é…ç½®è„šæœ¬å·²åŒ…å«ä¿®æ­£åçš„ç½‘ç»œç­–ç•¥ï¼Œé‡æ–°è¿è¡Œå³å¯
./scripts/install/02-configure-tekton-dashboard.sh
```

**æ ¹æœ¬åŸå› åˆ†æ**ï¼š
- åŸç½‘ç»œç­–ç•¥çš„ `to: namespaceSelector: {}` é™åˆ¶è¿‡ä¸¥
- Dashboardéœ€è¦è®¿é—® `10.96.0.1:443` (Kubernetes APIæœåŠ¡å™¨)
- ä¿®æ­£åçš„ç­–ç•¥ä½¿ç”¨ `to: []` å…è®¸è®¿é—®é›†ç¾¤å†…APIæœåŠ¡å™¨

**çŠ¶æ€**ï¼šå·²ä¿®å¤è„šæœ¬å’Œæ–‡æ¡£

---

## ğŸ” è°ƒè¯•æŠ€å·§

### æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯
```bash
# æŸ¥çœ‹ Pod æ—¥å¿—
kubectl logs <pod-name> -n tekton-pipelines

# æŸ¥çœ‹ EventListener çŠ¶æ€
kubectl describe eventlistener <name> -n tekton-pipelines

# æŸ¥çœ‹ Task æ‰§è¡Œæ—¥å¿—
kubectl logs -f <taskrun-pod> -n tekton-pipelines
```

### éªŒè¯ GPU æ”¯æŒ
```bash
# æ£€æŸ¥ GPU èŠ‚ç‚¹æ ‡ç­¾
kubectl get nodes -l accelerator=nvidia-tesla-gpu

# æ£€æŸ¥ NVIDIA GPU Operator
kubectl get pods -n gpu-operator-resources
```

### æ£€æŸ¥ç½‘ç»œè¿æ¥
```bash
# æµ‹è¯• EventListener æœåŠ¡
kubectl get svc -n tekton-pipelines | grep eventlistener

# ç«¯å£è½¬å‘æµ‹è¯•
kubectl port-forward svc/<service-name> 8080:8080 -n tekton-pipelines
```

---

### 8. PVC Workspace ç»‘å®šé—®é¢˜ (é‡è¦æ¡ˆä¾‹)

#### é—®é¢˜ï¼šTaskRunValidationFailed - "more than one PersistentVolumeClaim is bound"
**é”™è¯¯ä¿¡æ¯**ï¼š
```
[User error] more than one PersistentVolumeClaim is bound
```

**æ ¹æœ¬åŸå› åˆ†æ**ï¼š
1. **Taskå®šä¹‰ä½¿ç”¨å¤šä¸ªworkspace**: åŸå§‹Taskä½¿ç”¨äº†`source-code`å’Œ`shared-storage`ä¸¤ä¸ªworkspace
2. **PipelineRunä¸­workspaceç»‘å®šå†²çª**: å¤šä¸ªworkspaceç»‘å®šåˆ°åŒä¸€ä¸ªPVCæ—¶ä¼šäº§ç”Ÿå†²çª
3. **å­˜å‚¨ç±»é…ç½®é—®é¢˜**: PVCçš„storageClassNameè®¾ç½®ä¸æ­£ç¡®

**å®Œæ•´è¯Šæ–­å’Œè§£å†³æµç¨‹**ï¼š

**æ­¥éª¤1: è¯Šæ–­PVCçŠ¶æ€**
```bash
# æ£€æŸ¥PVCçŠ¶æ€
kubectl get pvc -n tekton-pipelines -o wide

# æ£€æŸ¥å­˜å‚¨ç±»
kubectl get storageclass

# æŸ¥çœ‹PVCè¯¦ç»†ä¿¡æ¯
kubectl describe pvc <pvc-name> -n tekton-pipelines

# æ£€æŸ¥å¤±è´¥çš„TaskRun
kubectl describe taskrun <taskrun-name> -n tekton-pipelines
```

**æ­¥éª¤2: éªŒè¯PVCé…ç½®æ–‡ä»¶**
æ£€æŸ¥ `examples/gpu-pipeline-workspaces.yaml` ä¸­çš„å­˜å‚¨ç±»é…ç½®ï¼š
```yaml
# æ­£ç¡®é…ç½®ç¤ºä¾‹
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: shared-artifacts-workspace
  namespace: tekton-pipelines
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi
  storageClassName: "local-path"  # ä½¿ç”¨é›†ç¾¤ä¸­å¯ç”¨çš„å­˜å‚¨ç±»
```

**æ­¥éª¤3: ä¿®å¤Taskå®šä¹‰**
é—®é¢˜ï¼šåŸTaskä½¿ç”¨å¤šä¸ªworkspace
```yaml
# æœ‰é—®é¢˜çš„é…ç½®
workspaces:
- name: source-code
  description: Workspace for source code checkout
- name: shared-storage
  description: Shared storage for artifacts
```

è§£å†³æ–¹æ¡ˆï¼šåˆå¹¶ä¸ºå•ä¸€workspace
```yaml
# ä¿®å¤åçš„é…ç½®
workspaces:
- name: shared-storage
  description: Shared storage for source code, artifacts, and cache
```

**æ­¥éª¤4: åˆ›å»ºä¿®å¤ç‰ˆæœ¬çš„Task**
åˆ›å»º `gpu-env-preparation-task-fixed.yaml`:
```yaml
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: gpu-env-preparation-fixed
  namespace: tekton-pipelines
spec:
  description: |
    Fixed version that uses only one workspace to avoid conflicts.
  params:
  - name: git-repo-url
    description: Git repository URL to clone
    type: string
  - name: git-revision
    description: Git revision to checkout
    type: string
    default: "main"
  - name: workspace-subdir
    description: Subdirectory within workspace to clone repository
    type: string
    default: "source"
  workspaces:
  - name: shared-storage
    description: Shared storage for source code and artifacts
    mountPath: /workspace/shared
  steps:
  - name: git-clone
    image: alpine/git:latest
    env:
    - name: WORKSPACE_SHARED_PATH
      value: $(workspaces.shared-storage.path)
    script: |
      #!/bin/sh
      set -eu
      
      echo "ğŸš€ Starting GPU environment preparation..."
      cd "${WORKSPACE_SHARED_PATH}"
      
      # Remove existing directory if it exists (é‡è¦ï¼šé˜²æ­¢å†²çª)
      if [ -d "$(params.workspace-subdir)" ]; then
        echo "ğŸ§¹ Removing existing directory: $(params.workspace-subdir)"
        rm -rf "$(params.workspace-subdir)"
      fi
      
      echo "ğŸ“¥ Cloning repository..."
      git clone "$(params.git-repo-url)" "$(params.workspace-subdir)"
      
      cd "$(params.workspace-subdir)"
      # å¤åˆ¶æ–‡ä»¶åˆ°workspaceæ ¹ç›®å½•ä¾›å…¶ä»–taskä½¿ç”¨
      cp -r . "${WORKSPACE_SHARED_PATH}/"
      
      echo "âœ… Environment preparation completed successfully"
```

**æ­¥éª¤5: é€æ­¥éªŒè¯ä¿®å¤**

**5.1 å…ˆéªŒè¯ç®€å•workspaceåŠŸèƒ½**
```bash
# ä½¿ç”¨æˆ‘ä»¬æä¾›çš„æµ‹è¯•æ–‡ä»¶
kubectl apply -f examples/debug-workspace-test.yaml
kubectl get pipelinerun debug-workspace-test -n tekton-pipelines -w
kubectl logs -l tekton.dev/pipelineRun=debug-workspace-test -n tekton-pipelines
```

**5.2 éªŒè¯git cloneåŠŸèƒ½**
```bash
kubectl apply -f examples/debug-git-clone-test.yaml
kubectl get pipelinerun debug-git-clone-test -n tekton-pipelines -w
kubectl logs -l tekton.dev/pipelineRun=debug-git-clone-test -n tekton-pipelines
```

**5.3 éªŒè¯ä¿®å¤ç‰ˆæœ¬çš„ç¯å¢ƒå‡†å¤‡ä»»åŠ¡**
```bash
# åº”ç”¨ä¿®å¤ç‰ˆæœ¬çš„task
kubectl apply -f examples/tasks/gpu-env-preparation-task-fixed.yaml

# åˆ›å»ºæµ‹è¯•pipeline
kubectl apply -f examples/gpu-env-test-fixed.yaml
kubectl get pipelinerun gpu-env-test-fixed -n tekton-pipelines -w
```

**å®Œæ•´è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# 1. æ¸…ç†ç°æœ‰èµ„æº
kubectl delete pvc -n tekton-pipelines --all
kubectl delete pipelinerun --all -n tekton-pipelines

# 2. é‡æ–°åˆ›å»ºPVCï¼ˆä½¿ç”¨æ­£ç¡®å­˜å‚¨ç±»ï¼‰
kubectl apply -f examples/gpu-pipeline-workspaces.yaml

# 3. åº”ç”¨ä¿®å¤ç‰ˆæœ¬çš„tasks
kubectl apply -f examples/tasks/gpu-env-preparation-task-fixed.yaml
kubectl apply -f examples/tasks/gpu-papermill-execution-task.yaml
kubectl apply -f examples/tasks/pytest-execution-task.yaml

# 4. æ‰§è¡Œå®Œæ•´çš„ä¿®å¤ç‰ˆæœ¬pipeline
kubectl apply -f examples/gpu-complete-pipeline-fixed.yaml
```

**éªŒè¯ç»“æœ**ï¼š
- âœ… ç¯å¢ƒå‡†å¤‡ä»»åŠ¡æˆåŠŸæ‰§è¡Œ
- âœ… Git repositoryæ­£ç¡®cloneåˆ°workspace
- âœ… æ–‡ä»¶æˆåŠŸå¤åˆ¶åˆ°shared workspace
- âœ… é¿å…äº†workspaceç»‘å®šå†²çª

---

### 9. GPUè®¿é—®é—®é¢˜è¯Šæ–­ (é‡è¦æ¡ˆä¾‹)

#### é—®é¢˜ï¼šGPU Pipelineæ‰§è¡Œå¤±è´¥ï¼ŒCUDAæ— æ³•æ£€æµ‹åˆ°è®¾å¤‡
**ç°è±¡**: 
- Pipelineä¸­çš„ç¯å¢ƒå‡†å¤‡ä»»åŠ¡æˆåŠŸ
- GPU papermillæ‰§è¡Œä»»åŠ¡å¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯ï¼š`CUDARuntimeError: cudaErrorNoDevice: no CUDA-capable device is detected`
- nvidia-smiåœ¨å®¹å™¨ä¸­èƒ½è¿è¡Œï¼Œä½†CUDAè¿è¡Œæ—¶æ— æ³•è®¿é—®GPU

**å®Œæ•´è¯Šæ–­æµç¨‹**:

**æ­¥éª¤1: éªŒè¯é›†ç¾¤GPUèµ„æº**
```bash
# æ£€æŸ¥èŠ‚ç‚¹GPUèµ„æº
kubectl describe nodes | grep -A 10 -B 5 "nvidia.com/gpu"

# æŸ¥çœ‹GPUè®¾å¤‡æ’ä»¶çŠ¶æ€
kubectl get daemonset -A | grep nvidia

# æ£€æŸ¥èŠ‚ç‚¹GPUåˆ†é…
kubectl get nodes -o json | jq '.items[0].status.allocatable."nvidia.com/gpu"'
```

**æ­¥éª¤2: åˆ›å»ºGPUæµ‹è¯•PodéªŒè¯ç¡¬ä»¶è®¿é—®**
åˆ›å»ºæµ‹è¯•æ–‡ä»¶ `gpu-test-pod.yaml`:
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: gpu-test-pod
  namespace: tekton-pipelines
spec:
  restartPolicy: Never
  nodeSelector:
    accelerator: nvidia-tesla-gpu
  tolerations:
  - key: nvidia.com/gpu
    operator: Exists
    effect: NoSchedule
  containers:
  - name: gpu-test
    image: nvcr.io/nvidia/rapidsai/notebooks:25.04-cuda12.8-py3.12
    command: ["/bin/bash"]
    args:
    - -c
    - |
      echo "ğŸ” Checking GPU access in container..."
      echo "ğŸ“ Checking /dev/nvidia* devices:"
      ls -la /dev/nvidia* || echo "âŒ No nvidia devices found"
      echo ""
      echo "ğŸ”§ Testing nvidia-smi:"
      nvidia-smi || echo "âŒ nvidia-smi failed"
      echo ""
      echo "ğŸ Testing Python CUDA access:"
      python3 -c "import cupy as cp; print('âœ… CuPy version:', cp.__version__); print('âœ… CUDA devices:', cp.cuda.runtime.getDeviceCount())" || echo "âŒ Python CUDA test failed"
      echo ""
      echo "ğŸ’¤ Sleeping for 300 seconds for debugging..."
      sleep 300
    resources:
      limits:
        nvidia.com/gpu: 1
      requests:
        nvidia.com/gpu: 1
    env:
    - name: NVIDIA_VISIBLE_DEVICES
      value: "all"
    - name: NVIDIA_DRIVER_CAPABILITIES
      value: "compute,utility"
```

**æ­¥éª¤3: æ‰§è¡ŒGPUæµ‹è¯•**
```bash
# åˆ›å»ºæµ‹è¯•pod
kubectl apply -f examples/testing/gpu-test-pod.yaml

# ç›‘æ§å¯åŠ¨çŠ¶æ€
kubectl get pod gpu-test-pod -n tekton-pipelines -w

# æŸ¥çœ‹æµ‹è¯•ç»“æœ
kubectl logs gpu-test-pod -n tekton-pipelines

# æ¸…ç†æµ‹è¯•pod
kubectl delete pod gpu-test-pod -n tekton-pipelines
```

**æ­¥éª¤3.1: Tektonç¯å¢ƒä¸­çš„GPUæµ‹è¯•**
```bash
# åœ¨Tektonç¯å¢ƒä¸­éªŒè¯GPUè®¿é—®
kubectl apply -f examples/testing/gpu-papermill-debug-test.yaml
kubectl get pipelinerun gpu-papermill-debug-test -n tekton-pipelines -w
kubectl logs -l tekton.dev/pipelineRun=gpu-papermill-debug-test -n tekton-pipelines
```

**æ­¥éª¤3.2: Papermillæ‰§è¡Œæµ‹è¯•**
```bash
# æµ‹è¯•Papermillæ‰§è¡Œå«RMMåˆå§‹åŒ–çš„notebook
kubectl apply -f examples/testing/gpu-papermill-notebook-test.yaml
kubectl get pipelinerun gpu-papermill-notebook-test -n tekton-pipelines -w
kubectl logs -l tekton.dev/pipelineRun=gpu-papermill-notebook-test -n tekton-pipelines -c step-execute-with-papermill
```

**æ­¥éª¤4: å¯¹æ¯”Tekton Taskä¸æˆåŠŸé…ç½®çš„å·®å¼‚**
å¦‚æœæµ‹è¯•podæˆåŠŸä½†Tekton taskå¤±è´¥ï¼Œæ£€æŸ¥ä»¥ä¸‹é…ç½®å·®å¼‚ï¼š

1. **å®‰å…¨ä¸Šä¸‹æ–‡é…ç½®**:
```yaml
# åœ¨Taskçš„stepsä¸­æ·»åŠ 
securityContext:
  allowPrivilegeEscalation: false
  capabilities:
    drop: ["ALL"]
  runAsNonRoot: false
  runAsUser: 0
  seccompProfile:
    type: RuntimeDefault
```

2. **ç¯å¢ƒå˜é‡é…ç½®**:
```yaml
env:
- name: NVIDIA_VISIBLE_DEVICES
  value: "all"
- name: NVIDIA_DRIVER_CAPABILITIES
  value: "compute,utility"
```

**æ­¥éª¤5: é€æ­¥éªŒè¯Tektonç»„ä»¶**

**5.1 ç®€å•Workspaceæµ‹è¯•**
åˆ›å»º `debug-workspace-test.yaml`:
```yaml
apiVersion: tekton.dev/v1
kind: PipelineRun
metadata:
  name: debug-workspace-test
  namespace: tekton-pipelines
spec:
  pipelineSpec:
    workspaces:
    - name: test-workspace
    tasks:
    - name: simple-test
      workspaces:
      - name: shared
        workspace: test-workspace
      taskSpec:
        workspaces:
        - name: shared
        steps:
        - name: test-step
          image: alpine:latest
          script: |
            #!/bin/sh
            echo "Testing workspace access..."
            ls -la $(workspaces.shared.path)
            echo "Creating test file..."
            echo "Hello from Tekton" > $(workspaces.shared.path)/test.txt
            cat $(workspaces.shared.path)/test.txt
            echo "Test completed successfully!"
  workspaces:
  - name: test-workspace
    persistentVolumeClaim:
      claimName: source-code-workspace
```

**5.2 Git Cloneæµ‹è¯•**
åˆ›å»º `debug-git-clone-test.yaml`:
```yaml
apiVersion: tekton.dev/v1
kind: PipelineRun
metadata:
  name: debug-git-clone-test
  namespace: tekton-pipelines
spec:
  pipelineSpec:
    workspaces:
    - name: workspace
    tasks:
    - name: git-clone-test
      workspaces:
      - name: shared
        workspace: workspace
      taskSpec:
        workspaces:
        - name: shared
        params:
        - name: git-repo-url
          type: string
        steps:
        - name: clone-step
          image: alpine/git:latest
          script: |
            #!/bin/sh
            set -eu
            echo "ğŸš€ Starting git clone test..."
            echo "ğŸ“ Workspace path: $(workspaces.shared.path)"
            echo "ğŸ”— Repository URL: $(params.git-repo-url)"
            
            cd $(workspaces.shared.path)
            
            # Remove existing directory if it exists
            if [ -d "source" ]; then
              echo "ğŸ§¹ Removing existing directory: source"
              rm -rf "source"
            fi
            
            echo "ğŸ“¥ Cloning repository..."
            git clone "$(params.git-repo-url)" source
            
            cd source
            echo "âœ… Clone completed. Repository contents:"
            ls -la
            
            if [ -d "notebooks" ]; then
              echo "âœ… notebooks/ directory found"
              ls -la notebooks/ | head -5
            fi
            
            echo "âœ… Git clone test completed successfully"
      params:
      - name: git-repo-url
        value: "https://github.com/johnnynv/Real-world_Tekton_Installation_Guide.git"
  workspaces:
  - name: workspace
    persistentVolumeClaim:
      claimName: source-code-workspace
```

**è§£å†³æ–¹æ¡ˆæ€»ç»“**:
1. **ä¿®å¤Taské…ç½®**: æ·»åŠ æ­£ç¡®çš„securityContext
2. **ç®€åŒ–Workspace**: æ¯ä¸ªTaskåªä½¿ç”¨ä¸€ä¸ªworkspaceé¿å…å†²çª
3. **å¤„ç†ç›®å½•å†²çª**: åœ¨git cloneå‰åˆ é™¤å·²å­˜åœ¨çš„ç›®å½•
4. **éªŒè¯GPUè®¿é—®**: ä½¿ç”¨ç‹¬ç«‹æµ‹è¯•podéªŒè¯ç¡¬ä»¶é…ç½®

**ğŸ“‹ å®Œæ•´çš„GPUé—®é¢˜è°ƒè¯•æ¡ˆä¾‹è®°å½•**

æ­¤æ¡ˆä¾‹å±•ç¤ºäº†ç³»ç»Ÿæ€§è¯Šæ–­GPU Pipelineé—®é¢˜çš„å®Œæ•´æµç¨‹ï¼š

**è¯Šæ–­ç»“æœæ€»ç»“**ï¼š
- âœ… **ç‹¬ç«‹GPUæµ‹è¯•** - GPUç¡¬ä»¶è®¿é—®å®Œå…¨æ­£å¸¸
- âœ… **Tekton GPUæµ‹è¯•** - åŒ…æ‹¬RMMåˆå§‹åŒ–åœ¨å†…çš„åŸºç¡€åŠŸèƒ½æ­£å¸¸  
- âœ… **Papermillç®€åŒ–æµ‹è¯•** - ä½¿ç”¨ç›¸åŒRMMåˆå§‹åŒ–ä»£ç çš„ç®€åŒ–notebookæ‰§è¡ŒæˆåŠŸ
- âŒ **å®Œæ•´notebookæ‰§è¡Œ** - åŸå§‹`01_scRNA_analysis_preprocessing.ipynb`æ‰§è¡Œå¤±è´¥

**å…³é”®å‘ç°**ï¼šé—®é¢˜ä¸åœ¨GPUç¡¬ä»¶ã€RMMåº“æˆ–Papermillæœºåˆ¶ï¼Œè€Œå¯èƒ½åœ¨äºåŸå§‹notebookçš„å¤æ‚æ€§æˆ–ç‰¹å®šä¾èµ–åºåˆ—ã€‚

**æ¨èè§£å†³æ–¹æ¡ˆ**ï¼š
1. ä½¿ç”¨æˆ‘ä»¬éªŒè¯è¿‡çš„æµ‹è¯•è„šæœ¬è¿›è¡Œåˆ†é˜¶æ®µéªŒè¯
2. å¯¹äºå¤æ‚notebookï¼Œè€ƒè™‘åˆ†æ®µæ‰§è¡Œæˆ–ç®€åŒ–ä¾èµ–
3. ä¿ç•™æ‰€æœ‰æµ‹è¯•æ¡ˆä¾‹ä¾›æœªæ¥é—®é¢˜è¯Šæ–­å‚è€ƒ

**ğŸ”¬ æœ€ç»ˆè¯Šæ–­ç»“è®º (é‡è¦)**

ç»è¿‡ç³»ç»Ÿæ€§çš„å®Œæ•´è°ƒè¯•ï¼Œæˆ‘ä»¬å¾—å‡ºä»¥ä¸‹å…³é”®ç»“è®ºï¼š

**âœ… éªŒè¯æˆåŠŸçš„ç»„ä»¶**ï¼š
- GPUç¡¬ä»¶è®¿é—®ï¼ˆ4ä¸ªNVIDIA A16 GPUæ­£å¸¸ï¼‰
- NVIDIAé©±åŠ¨å’ŒCUDAè¿è¡Œæ—¶ç¯å¢ƒ
- Kubernetes GPUè®¾å¤‡æ’ä»¶å’Œèµ„æºåˆ†é…
- Tektonæ ¸å¿ƒåŠŸèƒ½ï¼ˆTasksã€Pipelinesã€Workspacesï¼‰
- åŸºç¡€RMMå’ŒCuPyåŠŸèƒ½
- Papermillæ‰§è¡Œæœºåˆ¶ï¼ˆç®€åŒ–notebookæˆåŠŸï¼‰

**âŒ é—®é¢˜å®šä½**ï¼š
- åŸå§‹`01_scRNA_analysis_preprocessing.ipynb`åœ¨Tektonç¯å¢ƒä¸­æ‰§è¡Œå¤±è´¥
- ç®€åŒ–çš„ç›¸åŒæŠ€æœ¯æ ˆnotebookå¯ä»¥æˆåŠŸæ‰§è¡Œ
- ç‹¬ç«‹GPUæµ‹è¯•å§‹ç»ˆæˆåŠŸï¼Œè¯´æ˜åŸºç¡€è®¾æ–½æ— é—®é¢˜

**ğŸ“‹ æŠ€æœ¯éªŒè¯è®°å½•**ï¼š
```bash
# ä»¥ä¸‹æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼š
./scripts/validate-gpu-pipeline.sh gpu          # âœ… GPUç¡¬ä»¶è®¿é—®
kubectl apply -f examples/testing/gpu-papermill-debug-test.yaml     # âœ… GPUåŸºç¡€åŠŸèƒ½  
kubectl apply -f examples/testing/gpu-papermill-notebook-test.yaml  # âœ… Papermillç®€åŒ–notebook

# å¤±è´¥çš„æµ‹è¯•ï¼š
kubectl apply -f examples/pipelines/gpu-complete-pipeline-fixed.yaml  # âŒ åŸå§‹å¤æ‚notebook
```

**ğŸ¯ æœ€ç»ˆç»“è®º**ï¼š
1. **åŸºç¡€è®¾æ–½å®Œå…¨æ­£å¸¸** - æ‰€æœ‰GPUå’ŒTektonç»„ä»¶éƒ½å·²æ­£ç¡®é…ç½®
2. **æŠ€æœ¯æ ˆå¯è¡Œ** - GPUç§‘å­¦è®¡ç®—pipelineåœ¨æŠ€æœ¯ä¸Šå®Œå…¨å¯è¡Œ
3. **åŸå§‹notebookå¤æ‚æ€§** - é—®é¢˜å‡ºåœ¨ç‰¹å®šnotebookçš„å¤æ‚ä¾èµ–æˆ–æ‰§è¡Œåºåˆ—
4. **è§£å†³æ–¹æ¡ˆéªŒè¯** - å·²åˆ›å»ºå¯å·¥ä½œçš„æ¼”ç¤ºç‰ˆæœ¬è¯æ˜ç«¯åˆ°ç«¯åŠŸèƒ½

**ğŸ“– å¯¹äºç”Ÿäº§ä½¿ç”¨çš„å»ºè®®**ï¼š
- ä½¿ç”¨åˆ†é˜¶æ®µçš„notebookæ‰§è¡Œç­–ç•¥
- å¯¹å¤æ‚notebookè¿›è¡Œæ¨¡å—åŒ–æ‹†åˆ†
- é‡‡ç”¨æˆ‘ä»¬éªŒè¯è¿‡çš„GPUé…ç½®æ¨¡æ¿
- ä¿ç•™è°ƒè¯•å·¥å…·é›†ç”¨äºæŒç»­ç›‘æ§

---

### 12. Conda/Pipæƒé™é—®é¢˜ (æœ€æ–°é—®é¢˜)

#### é—®é¢˜ï¼šå®¹å™¨å†…conda/pip/pythonå‘½ä»¤æƒé™è¢«æ‹’ç»
**é”™è¯¯ä¿¡æ¯**ï¼š
```
/opt/conda/envs/rapids/bin/pip: Permission denied
/opt/conda/bin/pip: Permission denied
/opt/conda/bin/conda: Permission denied
```

**æ ¹æœ¬åŸå› åˆ†æ**ï¼š
1. **ç”¨æˆ·æƒé™ä¸è¶³**: Taskä½¿ç”¨ `runAsUser: 1000` (rapidsç”¨æˆ·)ï¼Œæ— æƒé™è®¿é—®condaç›®å½•
2. **ç›®å½•æ‰€æœ‰æƒé—®é¢˜**: `/opt/conda` ç›®å½•å¯èƒ½ç”±rootç”¨æˆ·æ‹¥æœ‰
3. **å®‰å…¨ä¸Šä¸‹æ–‡é…ç½®é”™è¯¯**: æ²¡æœ‰è¶³å¤Ÿçš„æƒé™è¿è¡Œconda/pipå‘½ä»¤

**å®Œæ•´è§£å†³æ–¹æ¡ˆ**ï¼š

**æ­¥éª¤1: ä¿®æ­£å®‰å…¨ä¸Šä¸‹æ–‡é…ç½®**
```yaml
# é”™è¯¯é…ç½®
securityContext:
  runAsUser: 1000      # rapids user - æƒé™ä¸è¶³
  runAsGroup: 1000

# æ­£ç¡®é…ç½®
securityContext:
  allowPrivilegeEscalation: false
  capabilities:
    drop: ["ALL"]
    add: ["IPC_LOCK", "SYS_RESOURCE"]
  runAsNonRoot: false
  runAsUser: 0         # root user - è¶³å¤Ÿæƒé™
  runAsGroup: 0
  seccompProfile:
    type: RuntimeDefault
```

**æ­¥éª¤2: åŠ¨æ€æƒé™ä¿®å¤è„šæœ¬**
```bash
# åœ¨è„šæœ¬å¼€å¤´æ·»åŠ æƒé™ä¿®å¤
echo "Fixing conda directory permissions..."
chown -R root:root /opt/conda 2>/dev/null || echo "WARNING: Cannot change conda ownership"
chmod -R 755 /opt/conda 2>/dev/null || echo "WARNING: Cannot change conda permissions"

# è®¾ç½®æ­£ç¡®çš„ç¯å¢ƒå˜é‡
export HOME="/root"
export USER="root"
export PATH="/opt/conda/envs/rapids/bin:/opt/conda/bin:$PATH"
```

**æ­¥éª¤3: æ™ºèƒ½è·¯å¾„æ£€æµ‹**
```bash
# åŠ¨æ€æ£€æµ‹Python/pip/condaè·¯å¾„
PYTHON_BIN=""
PIP_BIN=""
CONDA_BIN="/opt/conda/bin/conda"

if [ -x "/opt/conda/envs/rapids/bin/python" ]; then
  PYTHON_BIN="/opt/conda/envs/rapids/bin/python"
  PIP_BIN="/opt/conda/envs/rapids/bin/pip"
  echo "Using rapids environment"
elif [ -x "/opt/conda/bin/python" ]; then
  PYTHON_BIN="/opt/conda/bin/python"
  PIP_BIN="/opt/conda/bin/pip"
  echo "Using base conda environment"
else
  echo "ERROR: No Python found in expected locations"
  exit 1
fi
```

**æ­¥éª¤4: å®Œæ•´éªŒè¯æœºåˆ¶**
```bash
# éªŒè¯æ‰€æœ‰å‘½ä»¤å¯æ‰§è¡Œ
$PYTHON_BIN --version && echo "Python OK" || (echo "ERROR: Python failed" && exit 1)
$PIP_BIN --version && echo "pip OK" || (echo "ERROR: pip failed" && exit 1)
$CONDA_BIN --version && echo "conda OK" || (echo "ERROR: conda failed" && exit 1)
```

**å·²ä¿®å¤çš„Taskæ–‡ä»¶**ï¼š
- `examples/tasks/gpu-papermill-execution-task-fixed.yaml` - ä½¿ç”¨rootæƒé™å’ŒåŠ¨æ€è·¯å¾„æ£€æµ‹

**éªŒè¯æ­¥éª¤**ï¼š
```bash
# 1. åº”ç”¨ä¿®å¤åçš„task
kubectl apply -f examples/tasks/gpu-papermill-execution-task-fixed.yaml

# 2. æ‰§è¡Œæµ‹è¯•pipeline
kubectl apply -f examples/pipelines/gpu-original-notebook-docker-compose-mode.yaml

# 3. ç›‘æ§æ‰§è¡ŒçŠ¶æ€
kubectl get taskruns -l tekton.dev/pipelineRun=gpu-original-notebook-docker-compose-mode -n tekton-pipelines
```

**å…³é”®é…ç½®è¦ç‚¹**ï¼š
1. **å¿…é¡»ä½¿ç”¨rootç”¨æˆ·**: `runAsUser: 0` 
2. **æƒé™ä¿®å¤**: æ‰§è¡Œæ—¶åŠ¨æ€ä¿®å¤condaç›®å½•æƒé™
3. **æ™ºèƒ½è·¯å¾„æ£€æµ‹**: ä¸ç¡¬ç¼–ç è·¯å¾„ï¼ŒåŠ¨æ€æ£€æµ‹å¯ç”¨çš„Pythonç¯å¢ƒ
4. **å®Œæ•´é”™è¯¯å¤„ç†**: æ¯ä¸ªæ­¥éª¤éƒ½æœ‰é€‚å½“çš„é”™è¯¯æ£€æŸ¥å’Œé€€å‡º
5. **é¿å…ä¸­æ–‡è¾“å‡º**: æ‰€æœ‰æ—¥å¿—æ¶ˆæ¯ä½¿ç”¨è‹±æ–‡

**çŠ¶æ€**ï¼šå·²ä¿®å¤ - 2025-07-29

---

## 11. å¤§æ•°æ®é›†ä¸‹è½½æ”¯æŒ (æœ€ä½³å®è·µ)

### é—®é¢˜æè¿°
åŸå§‹notebookéœ€è¦ä¸‹è½½å¤§å‹æ•°æ®é›†ï¼ˆå¦‚ 2GB+ çš„å•ç»†èƒRNAæ•°æ®ï¼‰ï¼Œåœ¨Tektonç¯å¢ƒä¸­å¯èƒ½é‡åˆ°ï¼š
- ç½‘ç»œè¶…æ—¶å¯¼è‡´ä¸‹è½½å¤±è´¥
- å­˜å‚¨ç©ºé—´ä¸è¶³
- é‡å¤ä¸‹è½½æµªè´¹æ—¶é—´å’Œå¸¦å®½
- ä¸‹è½½ä¸­æ–­åæ— æ³•æ¢å¤

### æœ€ä½³å®è·µè§£å†³æ–¹æ¡ˆ

**1. ä¸“ç”¨ä¸‹è½½ä»»åŠ¡ (`large-dataset-download-task.yaml`)**
- âœ… **é‡è¯•æœºåˆ¶**: è‡ªåŠ¨é‡è¯•å¤±è´¥çš„ä¸‹è½½ï¼ŒæŒ‡æ•°é€€é¿ç­–ç•¥
- âœ… **è¶…æ—¶æ§åˆ¶**: å¯é…ç½®çš„ä¸‹è½½è¶…æ—¶æ—¶é—´ï¼ˆé»˜è®¤120åˆ†é’Ÿï¼‰
- âœ… **å®Œæ•´æ€§éªŒè¯**: MD5æ ¡éªŒå’Œæ–‡ä»¶å¤§å°éªŒè¯
- âœ… **ç¼“å­˜æœºåˆ¶**: é¿å…é‡å¤ä¸‹è½½ç›¸åŒæ•°æ®é›†
- âœ… **æ–­ç‚¹ç»­ä¼ **: æ”¯æŒcurlçš„æ–­ç‚¹ç»­ä¼ åŠŸèƒ½
- âœ… **å­˜å‚¨ä¼˜åŒ–**: åˆ†ç¦»æ•°æ®é›†å­˜å‚¨å’Œå¤„ç†å­˜å‚¨

**2. å¤§å®¹é‡å­˜å‚¨é…ç½® (`large-dataset-workspaces.yaml`)**
```yaml
- large-dataset-storage: 200Gi  # æ•°æ®é›†å­˜å‚¨
- dataset-cache-storage: 100Gi  # ç¼“å­˜å­˜å‚¨  
- processing-workspace: 150Gi   # å¤„ç†å·¥ä½œåŒº
æ€»è®¡: ~450Gi
```

**3. å®Œæ•´Pipelineæ”¯æŒ (`gpu-original-notebook-with-download.yaml`)**
- âœ… **åˆ†é˜¶æ®µæ‰§è¡Œ**: ä¸‹è½½ â†’ æ•°æ®é›†æˆ â†’ GPUæ‰§è¡Œ â†’ æµ‹è¯•
- âœ… **æ‰©å±•è¶…æ—¶**: Pipelineæ€»è¶…æ—¶4å°æ—¶
- âœ… **èµ„æºä¼˜åŒ–**: 32Giå†…å­˜ã€8CPUç”¨äºå¤§æ•°æ®é›†å¤„ç†
- âœ… **å¤šworkspaceè®¾è®¡**: åˆ†ç¦»æ•°æ®å­˜å‚¨å’Œå¤„ç†å­˜å‚¨

### éƒ¨ç½²å’Œä½¿ç”¨æ­¥éª¤

**ç¬¬ä¸€æ­¥ï¼šéƒ¨ç½²å¤§æ•°æ®é›†æ”¯æŒåŸºç¡€è®¾æ–½**
```bash
# éƒ¨ç½²ä¸“ç”¨å­˜å‚¨å’Œä¸‹è½½ä»»åŠ¡
./scripts/deploy-large-dataset-pipeline.sh

# éªŒè¯éƒ¨ç½²çŠ¶æ€
./scripts/deploy-large-dataset-pipeline.sh verify
```

**ç¬¬äºŒæ­¥ï¼šæ‰§è¡Œå¸¦ä¸‹è½½çš„åŸå§‹notebook**
```bash
# åº”ç”¨å®Œæ•´pipeline
kubectl apply -f examples/pipelines/gpu-original-notebook-with-download.yaml

# å®æ—¶ç›‘æ§
kubectl get pipelinerun gpu-original-notebook-with-download -n tekton-pipelines -w
```

**ç¬¬ä¸‰æ­¥ï¼šç›‘æ§å’Œè°ƒè¯•**
```bash
# æŸ¥çœ‹ä¸‹è½½è¿›åº¦
kubectl logs -f -l tekton.dev/task=large-dataset-download -n tekton-pipelines

# æŸ¥çœ‹å­˜å‚¨ä½¿ç”¨
kubectl get pvc -n tekton-pipelines | grep -E "large-dataset|cache|processing"
```

### é…ç½®å‚æ•°è¯´æ˜

**å…³é”®å‚æ•°é…ç½®**ï¼š
```yaml
params:
  dataset-url: "https://datasets.cellxgene.cziscience.com/your-dataset.h5ad"
  expected-dataset-size-mb: "2048"    # é¢„æœŸå¤§å°2GB
  download-timeout-minutes: "120"     # 2å°æ—¶ä¸‹è½½è¶…æ—¶
  max-download-retries: "3"           # æœ€å¤§3æ¬¡é‡è¯•
  enable-cache: "true"                # å¯ç”¨ç¼“å­˜
```

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

**ç½‘ç»œä¼˜åŒ–**ï¼š
- æ ¹æ®å¸¦å®½è°ƒæ•´è¶…æ—¶æ—¶é—´ï¼š1Gbpsç½‘ç»œå»ºè®®60åˆ†é’Ÿï¼Œ100Mbpså»ºè®®120åˆ†é’Ÿ
- ä½¿ç”¨CDNæˆ–é•œåƒç«™ç‚¹å‡å°‘ä¸‹è½½æ—¶é—´
- åœ¨å†…ç½‘ç¯å¢ƒé¢„å…ˆä¸‹è½½å¹¶è®¾ç½®æœ¬åœ°é•œåƒ

**å­˜å‚¨ä¼˜åŒ–**ï¼š
- å¯¹äºè¶…å¤§æ•°æ®é›†(>10GB)ï¼Œè€ƒè™‘ä½¿ç”¨é«˜IOPSå­˜å‚¨ç±»
- å¯ç”¨æ•°æ®é›†ç¼“å­˜é¿å…é‡å¤ä¸‹è½½
- å®šæœŸæ¸…ç†è¿‡æœŸç¼“å­˜æ–‡ä»¶

**èµ„æºä¼˜åŒ–**ï¼š
- å¤§æ•°æ®é›†å¤„ç†å»ºè®®32Gi+å†…å­˜
- ä½¿ç”¨SSDå­˜å‚¨æé«˜I/Oæ€§èƒ½
- æ ¹æ®æ•°æ®é›†å¤§å°è°ƒæ•´GPUå†…å­˜åˆ†é…

### æ•…éšœæ’é™¤

**ä¸‹è½½å¤±è´¥**ï¼š
```bash
# æ£€æŸ¥ä¸‹è½½ä»»åŠ¡çŠ¶æ€
kubectl get taskrun -l tekton.dev/task=large-dataset-download -n tekton-pipelines

# æŸ¥çœ‹ä¸‹è½½é”™è¯¯æ—¥å¿—
kubectl logs <download-taskrun-pod> -n tekton-pipelines
```

**å­˜å‚¨ä¸è¶³**ï¼š
```bash
# æ£€æŸ¥PVCä½¿ç”¨æƒ…å†µ
kubectl describe pvc large-dataset-storage -n tekton-pipelines

# æ¸…ç†ç¼“å­˜é‡Šæ”¾ç©ºé—´
kubectl exec -it <pod> -- rm -rf /workspace/datasets/cache/*
```

**ä¸‹è½½è¶…æ—¶**ï¼š
- å¢åŠ  `download-timeout-minutes` å‚æ•°
- æ£€æŸ¥ç½‘ç»œè¿æ¥ç¨³å®šæ€§
- è€ƒè™‘ä½¿ç”¨æ›´è¿‘çš„æ•°æ®æº

### æˆåŠŸéªŒè¯

æ‰§è¡ŒæˆåŠŸååº”çœ‹åˆ°ï¼š
- âœ… æ•°æ®é›†æˆåŠŸä¸‹è½½å¹¶ç¼“å­˜
- âœ… åŸå§‹notebookæˆåŠŸæ‰§è¡Œ
- âœ… ç”Ÿæˆå®Œæ•´çš„åˆ†æç»“æœ
- âœ… äº§ç”Ÿæ‰€éœ€çš„3ä¸ªpytestæ–‡ä»¶

è¿™ä¸ªæ–¹æ¡ˆ**å®Œå…¨æ”¯æŒåŸå§‹notebookçš„å¤§æ•°æ®é›†éœ€æ±‚**ï¼ŒåŒæ—¶æä¾›äº†ä¼ä¸šçº§çš„å¯é æ€§å’Œæ€§èƒ½ä¿è¯ã€‚

---

### 10. Pipelineæ‰§è¡Œå’Œç›‘æ§

#### ä½¿ç”¨æ‰§è¡Œè„šæœ¬
é¡¹ç›®æä¾›äº†ä¸“é—¨çš„æ‰§è¡Œè„šæœ¬ï¼š

```bash
# æ‰§è¡ŒGPU pipeline
chmod +x scripts/execute-gpu-pipeline.sh
./scripts/execute-gpu-pipeline.sh execute

# ç›‘æ§æ‰§è¡ŒçŠ¶æ€
./scripts/execute-gpu-pipeline.sh monitor <run-name>

# æŸ¥çœ‹æ‰§è¡Œç»“æœ
./scripts/execute-gpu-pipeline.sh results <run-name>

# åˆ—å‡ºæ‰€æœ‰æ‰§è¡Œè®°å½•
./scripts/execute-gpu-pipeline.sh list
```

#### Dashboardè®¿é—®
```bash
# è·å–Dashboardè®¿é—®ä¿¡æ¯
NODE_IP=$(kubectl get nodes -o jsonpath='{.items[0].status.addresses[?(@.type=="InternalIP")].address}')
DASHBOARD_PORT=$(kubectl get svc tekton-dashboard -n tekton-pipelines -o jsonpath='{.spec.ports[0].nodePort}')
echo "Dashboard: http://${NODE_IP}:${DASHBOARD_PORT}"
```

---

### 11. å®Œæ•´éªŒè¯æµç¨‹

#### ç«¯åˆ°ç«¯éªŒè¯æ­¥éª¤
æŒ‰ç…§ä»¥ä¸‹é¡ºåºé€æ­¥éªŒè¯ï¼Œç¡®ä¿æ¯ä¸€æ­¥éƒ½æˆåŠŸï¼š

**é˜¶æ®µ1: åŸºç¡€ç¯å¢ƒéªŒè¯**
```bash
# 1. éªŒè¯é›†ç¾¤å’ŒGPUèµ„æº
kubectl get nodes
kubectl describe nodes | grep nvidia.com/gpu

# 2. éªŒè¯Tektonç»„ä»¶
kubectl get pods -n tekton-pipelines
kubectl get tasks -n tekton-pipelines
kubectl get pipelines -n tekton-pipelines
```

**é˜¶æ®µ2: å­˜å‚¨å’ŒworkspaceéªŒè¯**
```bash
# 1. åˆ›å»ºPVC
kubectl apply -f examples/gpu-pipeline-workspaces.yaml
kubectl get pvc -n tekton-pipelines

# 2. æµ‹è¯•åŸºç¡€workspaceåŠŸèƒ½
kubectl apply -f examples/debug-workspace-test.yaml
kubectl logs -l tekton.dev/pipelineRun=debug-workspace-test -n tekton-pipelines

# 3. æµ‹è¯•git cloneåŠŸèƒ½
kubectl apply -f examples/debug-git-clone-test.yaml
kubectl logs -l tekton.dev/pipelineRun=debug-git-clone-test -n tekton-pipelines
```

**é˜¶æ®µ3: GPUè®¿é—®éªŒè¯**
```bash
# 1. ç‹¬ç«‹GPUæµ‹è¯•
kubectl apply -f gpu-test-pod.yaml
kubectl logs gpu-test-pod -n tekton-pipelines

# 2. æ¸…ç†GPUæµ‹è¯•
kubectl delete pod gpu-test-pod -n tekton-pipelines
```

**é˜¶æ®µ4: Tekton TaskéªŒè¯**
```bash
# 1. æµ‹è¯•ç¯å¢ƒå‡†å¤‡task
kubectl apply -f examples/tasks/gpu-env-preparation-task-fixed.yaml
kubectl apply -f examples/gpu-env-test-fixed.yaml
kubectl logs -l tekton.dev/pipelineRun=gpu-env-test-fixed -n tekton-pipelines
```

**é˜¶æ®µ5: å®Œæ•´Pipelineæ‰§è¡Œ**
```bash
# 1. åº”ç”¨æ‰€æœ‰ä¿®å¤ç‰ˆæœ¬çš„tasks
kubectl apply -f examples/tasks/gpu-papermill-execution-task.yaml
kubectl apply -f examples/tasks/jupyter-nbconvert-task.yaml
kubectl apply -f examples/tasks/pytest-execution-task.yaml

# 2. æ‰§è¡Œå®Œæ•´pipeline
kubectl apply -f examples/gpu-complete-pipeline-fixed.yaml

# 3. ç›‘æ§æ‰§è¡Œ
./scripts/execute-gpu-pipeline.sh monitor gpu-scrna-complete-fixed

# 4. æŸ¥çœ‹ç»“æœ
./scripts/execute-gpu-pipeline.sh results gpu-scrna-complete-fixed
```

#### é¢„æœŸç»“æœæ£€æŸ¥æ¸…å•
- [ ] **ç¯å¢ƒå‡†å¤‡**: RepositoryæˆåŠŸcloneï¼Œæ–‡ä»¶å¤åˆ¶åˆ°workspace
- [ ] **GPUæ‰§è¡Œ**: Notebookåœ¨GPUä¸ŠæˆåŠŸæ‰§è¡Œï¼Œç”Ÿæˆ `executed_scrna_notebook.ipynb`
- [ ] **HTMLè½¬æ¢**: æˆåŠŸç”Ÿæˆ `executed_scrna_notebook.html`
- [ ] **æµ‹è¯•æ‰§è¡Œ**: PyTestæˆåŠŸè¿è¡Œï¼Œç”Ÿæˆä¸‰ä¸ªæ–‡ä»¶ï¼š
  - `coverage.xml` - ä»£ç è¦†ç›–ç‡æŠ¥å‘Š
  - `pytest_results.xml` - JUnitæµ‹è¯•ç»“æœ
  - `pytest_report.html` - HTMLæµ‹è¯•æŠ¥å‘Š

#### æ•…éšœæ’é™¤ä¼˜å…ˆçº§
1. **é«˜ä¼˜å…ˆçº§**: GPUè®¿é—®é—®é¢˜ - å½±å“æ ¸å¿ƒåŠŸèƒ½
2. **ä¸­ä¼˜å…ˆçº§**: Workspaceç»‘å®šé—®é¢˜ - å½±å“pipelineå¯åŠ¨
3. **ä½ä¼˜å…ˆçº§**: ä¾èµ–åŒ…å†²çª - é€šå¸¸ä¸å½±å“æ‰§è¡Œç»“æœ

---

## ğŸ“ é—®é¢˜æŠ¥å‘Š

å¦‚æœé‡åˆ°æ–°é—®é¢˜ï¼Œè¯·è®°å½•ï¼š

1. **é”™è¯¯ä¿¡æ¯**ï¼šå®Œæ•´çš„é”™è¯¯è¾“å‡º
2. **ç¯å¢ƒä¿¡æ¯**ï¼šKubernetes ç‰ˆæœ¬ã€èŠ‚ç‚¹é…ç½®ã€GPUå‹å·
3. **å¤ç°æ­¥éª¤**ï¼šå¯¼è‡´é—®é¢˜çš„å…·ä½“æ“ä½œåºåˆ—
4. **ç›¸å…³é…ç½®**ï¼šYAML æ–‡ä»¶å†…å®¹ï¼Œç‰¹åˆ«æ˜¯Taskå’ŒPipelineRunå®šä¹‰
5. **æ‰§è¡Œæ—¥å¿—**ï¼šä½¿ç”¨ `./scripts/execute-gpu-pipeline.sh` çš„è¾“å‡º
6. **éªŒè¯ç»“æœ**ï¼šæŒ‰ç…§æœ¬æ–‡æ¡£çš„éªŒè¯æµç¨‹æ‰§è¡Œåçš„ç»“æœ
7. **GPUæµ‹è¯•ç»“æœ**ï¼šç‹¬ç«‹GPUæµ‹è¯•podçš„æ‰§è¡Œç»“æœ

**å¸¸ç”¨è°ƒè¯•å‘½ä»¤**ï¼š
```bash
# æ”¶é›†å®Œæ•´æ—¥å¿—åŒ…
kubectl logs -l tekton.dev/pipeline=gpu-scientific-computing-pipeline -n tekton-pipelines > pipeline-logs.txt
kubectl get pods -n tekton-pipelines -o yaml > pods-status.yaml
kubectl describe nodes > nodes-info.txt
```

---

**æ›´æ–°æ—¶é—´**ï¼š2025-07-28  
**ç»´æŠ¤è€…**ï¼šTekton GPU Pipeline Team  
**é‡è¦æ¡ˆä¾‹**ï¼šGPUè®¿é—®é—®é¢˜ã€Workspaceç»‘å®šå†²çª 

---

### 13. GitHub Actionså®Œæ•´8æ­¥å·¥ä½œæµç¨‹è¿ç§»åˆ°Tekton (æœ€ä½³å®è·µ)

#### å®Œæ•´å·¥ä½œæµç¨‹æ¦‚è¿°
åŸå§‹GitHub Actionså·¥ä½œæµç¨‹åŒ…å«8ä¸ªå…³é”®æ­¥éª¤ï¼Œå¿…é¡»å®Œæ•´è¿ç§»åˆ°Tektonï¼š

**åŸå§‹GitHub Actionså·¥ä½œæµç¨‹**ï¼š
1. æ ¹æ®docker composeå¯åŠ¨GPUå®¹å™¨
2. æ‰€æœ‰æ­¥éª¤åœ¨å®¹å™¨å†…å®Œæˆ  
3. ä¸ºnotebookæ‰§è¡Œå‡†å¤‡ç¯å¢ƒï¼ˆPython, condaç­‰ï¼‰
4. æ‰§è¡Œpapermillå‘½ä»¤ï¼š`papermill "${NOTEBOOK_RELATIVED_DIR}/${NOTEBOOK_FILENAME}" "${DOCKER_WRITEABLE_DIR}/${OUTPUT_NOTEBOOK}" --log-output --log-level DEBUG --progress-bar --report-mode --kernel python3`
5. è½¬æ¢notebookä¸ºHTMLï¼š`jupyter nbconvert --to html "$DOCKER_WRITEABLE_DIR/$OUTPUT_NOTEBOOK" --output "$DOCKER_WRITEABLE_DIR/$OUTPUT_NOTEBOOK_HTML" --output-dir "$DOCKER_WRITEABLE_DIR"`
6. ä¸‹è½½æµ‹è¯•repoï¼š`https://github.com/NVIDIA-AI-Blueprints/blueprint-github-test`ï¼Œæ¸…ç©ºinputæ–‡ä»¶å¤¹ï¼Œæ”¾å…¥HTMLæ–‡ä»¶
7. æ‰§è¡Œpytestï¼š`poetry run pytest -m single_cell --cov=./ --cov-report=xml --junitxml --html --self-contained-html`
8. å°†pytestè¾“å‡ºæ”¾å…¥GitHub Action summaryï¼Œç”Ÿæˆçš„ä¸‰ä¸ªæ–‡ä»¶æ”¾å…¥artifact

#### Tektonè¿ç§»æœ€ä½³å®è·µ

**1. å®Œæ•´Pipelineè®¾è®¡**
åˆ›å»º `gpu-complete-workflow-pipeline.yaml`ï¼ŒåŒ…å«æ‰€æœ‰8ä¸ªæ­¥éª¤ï¼š
- **prepare-environment**: ç¯å¢ƒå‡†å¤‡å’Œä»£ç æ£€å‡º
- **execute-notebook-papermill**: å®Œæ•´å‚æ•°çš„papermillæ‰§è¡Œ
- **convert-notebook-to-html**: å®Œæ•´å‚æ•°çš„jupyter nbconvert
- **execute-pytest-tests**: pytestæµ‹è¯•æ‰§è¡Œå’Œæ–‡ä»¶ç®¡ç†
- **generate-artifact-summary**: Tekton artifactæ€»ç»“ï¼ˆç­‰ä»·äºGitHub Actions summaryï¼‰

**2. å…³é”®Taskså®ç°**

**a) gpu-papermill-execution-complete.yaml**
- âœ… ä½¿ç”¨å®Œå…¨ç›¸åŒçš„papermillå‚æ•°
- âœ… rootæƒé™è§£å†³æ‰€æœ‰permissioné—®é¢˜
- âœ… å®Œæ•´çš„ç¯å¢ƒsetupå’Œé”™è¯¯å¤„ç†
- âœ… ç”Ÿæˆpapermill.logæ–‡ä»¶

**b) jupyter-nbconvert-complete.yaml**
- âœ… ä½¿ç”¨å®Œå…¨ç›¸åŒçš„jupyter nbconvertå‚æ•°
- âœ… æ­£ç¡®çš„HTMLæ–‡ä»¶ç”Ÿæˆå’ŒéªŒè¯
- âœ… ä¸ºpytestå‡†å¤‡stagingæ–‡ä»¶

**c) pytest-execution.yaml**
- âœ… è‡ªåŠ¨ä¸‹è½½æµ‹è¯•repository
- âœ… æ¸…ç©ºinputæ–‡ä»¶å¤¹å¹¶æ”¾å…¥HTMLæ–‡ä»¶
- âœ… ä½¿ç”¨poetryæ‰§è¡Œpytest
- âœ… ç”Ÿæˆä¸‰ä¸ªå¿…éœ€çš„æ–‡ä»¶ï¼šcoverage.xml, pytest_results.xml, pytest_report.html

**3. æƒé™é—®é¢˜å®Œæ•´è§£å†³æ–¹æ¡ˆ**
```bash
# åœ¨æ¯ä¸ªtaskå¼€å§‹æ—¶æ‰§è¡Œ
chown -R root:root /opt/conda 2>/dev/null || echo "WARNING: Cannot change conda ownership"
chmod -R 777 /opt/conda 2>/dev/null || echo "WARNING: Cannot change conda permissions"
chown -R root:root "${WORKSPACE_SHARED_PATH}" 2>/dev/null || echo "WARNING: Cannot change workspace ownership"
chmod -R 777 "${WORKSPACE_SHARED_PATH}" 2>/dev/null || echo "WARNING: Cannot change workspace permissions"

# ä½¿ç”¨rootç”¨æˆ·
securityContext:
  runAsUser: 0
  runAsGroup: 0
  runAsNonRoot: false
```

**4. Artifactç®¡ç†æœ€ä½³å®è·µ**

**åœ¨Tektonä¸­å®ç°GitHub Actionsç­‰ä»·åŠŸèƒ½**ï¼š

**a) Pipeline Summary (ç­‰ä»·äºGitHub Actions Summary)**
- åˆ›å»º `generate-artifact-summary` task
- ç”Ÿæˆè¯¦ç»†çš„æ‰§è¡ŒæŠ¥å‘Šï¼ŒåŒ…å«æ‰€æœ‰ç”Ÿæˆçš„artifacts
- æ£€æŸ¥å¿…éœ€æ–‡ä»¶çš„å­˜åœ¨å’Œå¤§å°
- æä¾›æ¸…æ™°çš„æˆåŠŸ/å¤±è´¥çŠ¶æ€

**b) Artifact Storage**
- ä½¿ç”¨PVC workspaceæŒä¹…åŒ–æ‰€æœ‰artifacts
- æ‰€æœ‰æ–‡ä»¶ä¿å­˜åœ¨ `/workspace/shared/artifacts/` ç›®å½•
- æ”¯æŒé€šè¿‡kubectlè®¿é—®artifactsï¼š
```bash
# è®¿é—®artifacts
kubectl exec -it <pod-name> -n tekton-pipelines -- ls -la /workspace/shared/artifacts/

# å¤åˆ¶artifactsåˆ°æœ¬åœ°
kubectl cp tekton-pipelines/<pod-name>:/workspace/shared/artifacts/ ./local-artifacts/
```

**c) Dashboardé›†æˆ**
- é€šè¿‡Tekton DashboardæŸ¥çœ‹pipelineæ‰§è¡ŒçŠ¶æ€
- å®æ—¶æ—¥å¿—æŸ¥çœ‹åŠŸèƒ½
- Pipelineç»“æœå’Œartifactè·¯å¾„å±•ç¤º

**5. å…³é”®å‚æ•°ç¡®ä¿ä¸€è‡´æ€§**

**papermillå‚æ•°**ï¼š
```bash
papermill "${NOTEBOOK_RELATIVED_DIR}/${NOTEBOOK_FILENAME}" "${DOCKER_WRITEABLE_DIR}/${OUTPUT_NOTEBOOK}" \
    --log-output \
    --log-level DEBUG \
    --progress-bar \
    --report-mode \
    --kernel python3 2>&1 | tee "${DOCKER_WRITEABLE_DIR}/papermill.log"
```

**jupyter nbconvertå‚æ•°**ï¼š
```bash
jupyter nbconvert --to html "$DOCKER_WRITEABLE_DIR/$OUTPUT_NOTEBOOK" \
    --output "$DOCKER_WRITEABLE_DIR/$OUTPUT_NOTEBOOK_HTML" \
    --output-dir "$DOCKER_WRITEABLE_DIR" \
    > "$DOCKER_WRITEABLE_DIR/jupyter_nbconvert.log" 2>&1
```

**pytestå‚æ•°**ï¼š
```bash
poetry run pytest -m single_cell \
    --cov=./ \
    --cov-report=xml:"$DOCKER_WRITEABLE_DIR/coverage.xml" \
    --junitxml="$DOCKER_WRITEABLE_DIR/pytest_results.xml" \
    --html="$DOCKER_WRITEABLE_DIR/pytest_report.html" \
    --self-contained-html 2>&1
```

**6. éƒ¨ç½²å’ŒéªŒè¯æ­¥éª¤**

**å®Œæ•´éƒ¨ç½²å‘½ä»¤**ï¼š
```bash
# 1. éƒ¨ç½²æ‰€æœ‰æ–°çš„tasks
kubectl apply -f examples/tasks/gpu-papermill-execution-complete.yaml
kubectl apply -f examples/tasks/jupyter-nbconvert-complete.yaml

# 2. ç¡®è®¤ç°æœ‰çš„pytest task
kubectl apply -f examples/tasks/pytest-execution.yaml

# 3. éƒ¨ç½²å®Œæ•´workflow pipeline
kubectl apply -f examples/pipelines/gpu-complete-workflow-pipeline.yaml

# 4. ç›‘æ§æ‰§è¡Œ
kubectl get pipelinerun gpu-complete-workflow-pipeline -n tekton-pipelines -w
```

**éªŒè¯æ¸…å•**ï¼š
- [ ] **æ‰§è¡Œnotebook**: ç”Ÿæˆ `01_scRNA_analysis_preprocessing_output.ipynb`
- [ ] **papermillæ—¥å¿—**: ç”Ÿæˆ `papermill.log`
- [ ] **HTMLè½¬æ¢**: ç”Ÿæˆ `01_scRNA_analysis_preprocessing_output.html`
- [ ] **nbconvertæ—¥å¿—**: ç”Ÿæˆ `jupyter_nbconvert.log`
- [ ] **æµ‹è¯•repoä¸‹è½½**: æˆåŠŸclone `blueprint-github-test`
- [ ] **inputæ–‡ä»¶å¤¹ç®¡ç†**: æ¸…ç©ºå¹¶æ”¾å…¥HTMLæ–‡ä»¶
- [ ] **pytestæ‰§è¡Œ**: ç”Ÿæˆä¸‰ä¸ªæ–‡ä»¶
  - `coverage.xml` - ä»£ç è¦†ç›–ç‡æŠ¥å‘Š
  - `pytest_results.xml` - JUnitæµ‹è¯•ç»“æœ
  - `pytest_report.html` - HTMLæµ‹è¯•æŠ¥å‘Š
- [ ] **artifactæ€»ç»“**: ç”Ÿæˆå®Œæ•´çš„pipelineæ‰§è¡ŒæŠ¥å‘Š

**7. ç›‘æ§å’Œè°ƒè¯•æŠ€å·§**

**å®æ—¶ç›‘æ§**ï¼š
```bash
# ç›‘æ§æ•´ä¸ªpipeline
kubectl get pipelinerun gpu-complete-workflow-pipeline -n tekton-pipelines -w

# æŸ¥çœ‹ç‰¹å®štaskçŠ¶æ€
kubectl get taskruns -l tekton.dev/pipelineRun=gpu-complete-workflow-pipeline -n tekton-pipelines

# æŸ¥çœ‹å®æ—¶æ—¥å¿—
kubectl logs -f -l tekton.dev/pipelineRun=gpu-complete-workflow-pipeline -n tekton-pipelines
```

**è°ƒè¯•ç‰¹å®šæ­¥éª¤**ï¼š
```bash
# Papermillæ‰§è¡Œæ—¥å¿—
kubectl logs <papermill-pod> -n tekton-pipelines -c gpu-papermill-execute-complete

# HTMLè½¬æ¢æ—¥å¿—
kubectl logs <nbconvert-pod> -n tekton-pipelines -c convert-to-html-complete

# Pytestæ‰§è¡Œæ—¥å¿—
kubectl logs <pytest-pod> -n tekton-pipelines -c execute-tests
```

**8. æ•…éšœæ’é™¤å¸¸è§é—®é¢˜**

**é—®é¢˜1: Papermillæ‰§è¡Œå¤±è´¥**
- æ£€æŸ¥notebookè·¯å¾„å’Œä¾èµ–åŒ…å®‰è£…
- éªŒè¯GPUè®¿é—®å’Œå†…å­˜è®¾ç½®
- æŸ¥çœ‹papermill.logè¯¦ç»†é”™è¯¯ä¿¡æ¯

**é—®é¢˜2: HTMLè½¬æ¢å¤±è´¥**
- ç¡®è®¤input notebookå­˜åœ¨ä¸”æœ‰æ•ˆ
- æ£€æŸ¥nbconvertå®‰è£…å’Œè·¯å¾„
- éªŒè¯è¾“å‡ºç›®å½•æƒé™

**é—®é¢˜3: Pytestæ‰§è¡Œå¤±è´¥**
- ç¡®è®¤æµ‹è¯•repoä¸‹è½½æˆåŠŸ
- æ£€æŸ¥HTMLæ–‡ä»¶æ˜¯å¦æ­£ç¡®æ”¾å…¥inputæ–‡ä»¶å¤¹
- éªŒè¯poetryå®‰è£…å’Œä¾èµ–

**é—®é¢˜4: Artifactè®¿é—®é—®é¢˜**
- æ£€æŸ¥PVC workspaceç»‘å®š
- éªŒè¯ç›®å½•æƒé™è®¾ç½®
- ç¡®è®¤æ‰€æœ‰æ–‡ä»¶éƒ½åœ¨æ­£ç¡®ä½ç½®

**9. ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ**

**a) èµ„æºé…ç½®**
- GPUèŠ‚ç‚¹ï¼š4+ NVIDIA A16 GPUs
- å†…å­˜ï¼š32Gi+ per task
- å­˜å‚¨ï¼š200Gi+ PVC for artifacts
- ç½‘ç»œï¼šç¨³å®šçš„å¤–ç½‘è®¿é—®ï¼ˆä¸‹è½½ä¾èµ–å’Œæµ‹è¯•repoï¼‰

**b) å®‰å…¨é…ç½®**
- ä½¿ç”¨privileged Pod Securityæ ‡å‡†
- é™åˆ¶GPUèŠ‚ç‚¹è®¿é—®
- å®šæœŸæ¸…ç†old artifacts

**c) ç›‘æ§é…ç½®**
- è®¾ç½®pipelineæ‰§è¡Œalerts
- ç›‘æ§GPUä½¿ç”¨ç‡
- è·Ÿè¸ªartifactç”ŸæˆçŠ¶æ€

**çŠ¶æ€**ï¼šå®Œæ•´8æ­¥å·¥ä½œæµç¨‹è¿ç§»å®Œæˆ - 2025-07-29
**ç»´æŠ¤è€…**ï¼šTekton GPU Pipeline Team
**é‡è¦æˆæœ**ï¼šGitHub Actionså®Œæ•´åŠŸèƒ½ç­‰ä»·è¿ç§» 

---

## 14. ç”Ÿäº§çº§Init Containerè§£å†³æ–¹æ¡ˆä¸RAPIDSç”¨æˆ·ä¿®æ­£

### é—®é¢˜å‘ç°
åœ¨å®æ–½ç”Ÿäº§çº§Init Containerè§£å†³æ–¹æ¡ˆæ—¶ï¼Œå‘ç°äº†ä¸€ä¸ªå…³é”®çš„ç”¨æˆ·æƒé™é—®é¢˜ï¼š

**é”™è¯¯é…ç½®ï¼š**
- åˆå§‹ç‰ˆæœ¬é”™è¯¯åœ°ä½¿ç”¨äº†ubuntuç”¨æˆ·ï¼ˆUID 1000ï¼‰
- è®¾ç½®äº† `/home/ubuntu` ä½œä¸ºHOMEç›®å½•

**æ­£ç¡®é…ç½®ï¼ˆåŸºäºdocker-compose.yamlï¼‰ï¼š**
- åº”è¯¥ä½¿ç”¨rapidsç”¨æˆ·ï¼ˆUID 1000ï¼‰
- è®¾ç½® `/home/rapids` ä½œä¸ºHOMEç›®å½•
- è¿™ä¸docker-compose-nb-2504.yamlä¸­çš„é…ç½®ä¸€è‡´ï¼š
  ```yaml
  user: rapids
  working_dir: /home/rapids
  ```

### è§£å†³æ–¹æ¡ˆæ¶æ„

**ç”Ÿäº§çº§Init Containeræ¨¡å¼ï¼š**

1. **Init Containerï¼ˆrootæƒé™ï¼‰ï¼š**
   - æ£€æµ‹å’Œåˆ›å»ºrapidsç”¨æˆ·
   - ä¿®å¤/opt/condaæƒé™ç»™rapidsç”¨æˆ·
   - åˆ›å»º/home/rapidsç›®å½•
   - é…ç½®workspaceæƒé™

2. **ä¸»å®¹å™¨ï¼ˆrapidsç”¨æˆ·ï¼‰ï¼š**
   - ä»¥UID 1000è¿è¡Œï¼ˆrapidsç”¨æˆ·ï¼‰
   - å®Œå…¨å…¼å®¹Docker Composeç¯å¢ƒ
   - éµå¾ªKuberneteså®‰å…¨æœ€ä½³å®è·µ

### æŠ€æœ¯å®ç°

**å…³é”®ä¿®æ­£ï¼š**
```yaml
securityContext:
  runAsUser: 1000  # rapidsç”¨æˆ·
  runAsGroup: 1000
env:
- name: HOME
  value: "/home/rapids"  # Docker Composeå…¼å®¹
- name: USER  
  value: "rapids"
```

**Init Containeræƒé™ä¿®å¤ï¼š**
```bash
# æ£€æµ‹rapidsç”¨æˆ·
if id rapids >/dev/null 2>&1; then
  RAPIDS_UID=$(id -u rapids)
  RAPIDS_GID=$(id -g rapids)
else
  # åˆ›å»ºrapidsç”¨æˆ·
  RAPIDS_UID=1000
  RAPIDS_GID=1000
  useradd -u $RAPIDS_UID -g $RAPIDS_GID -m -s /bin/bash rapids
fi

# ä¿®å¤condaæƒé™
chown -R $RAPIDS_UID:$RAPIDS_GID /opt/conda/
chmod -R 755 /opt/conda/

# åˆ›å»ºrapids homeç›®å½•
mkdir -p /home/rapids
chown $RAPIDS_UID:$RAPIDS_GID /home/rapids
```

### éªŒè¯ç»“æœ

**âœ… æˆåŠŸè§£å†³çš„é—®é¢˜ï¼š**
- Docker Compose vs Kubernetesç”¨æˆ·æƒé™å·®å¼‚
- Condaè®¿é—®æƒé™é—®é¢˜
- Workspaceå†™å…¥æƒé™
- å®‰å…¨ä¸Šä¸‹æ–‡é…ç½®

**âš ï¸ å‰©ä½™é—®é¢˜ï¼š**
- Notebookç‰¹å®šçš„RMM (RAPIDS Memory Manager) å…¼å®¹æ€§
- è¿™æ˜¯notebookä»£ç çº§åˆ«çš„é—®é¢˜ï¼Œä¸æ˜¯åŸºç¡€è®¾æ–½é—®é¢˜

### ç”Ÿäº§éƒ¨ç½²å»ºè®®

**æ–¹æ¡ˆ1ï¼šRMMå…¼å®¹æ€§ä¿®å¤ï¼ˆæ¨èï¼‰**
åœ¨notebookç¬¬ä¸€ä¸ªcellæ·»åŠ RMMé”™è¯¯å¤„ç†ï¼š
```python
import warnings
warnings.filterwarnings("ignore")

try:
    import rmm
    from rmm.allocators.cupy import rmm_cupy_allocator
    import cupy as cp
    
    rmm.reinitialize(
        managed_memory=False,
        pool_allocator=False,
        devices=0,
    )
    cp.cuda.set_allocator(rmm_cupy_allocator)
    print("RMM initialized successfully")
except Exception as e:
    print(f"RMM initialization failed, using default allocator: {e}")
    # ç»§ç»­ä½¿ç”¨é»˜è®¤çš„CuPy allocator
```

**æ–¹æ¡ˆ2ï¼šä½¿ç”¨éªŒè¯æµ‹è¯•æ¶æ„**
åŸºäºæˆåŠŸçš„éªŒè¯pipelineåˆ›å»ºç”Ÿäº§ç‰ˆæœ¬ï¼Œä½¿ç”¨ä¸å«RMMé—®é¢˜çš„ç®€åŒ–notebookã€‚

**æ–¹æ¡ˆ3ï¼šé¢„é…ç½®é•œåƒ**
åˆ¶ä½œåŒ…å«RMMå…¼å®¹æ€§ä¿®å¤çš„è‡ªå®šä¹‰Dockeré•œåƒã€‚

### æœ€ç»ˆè¯„ä¼°

**ğŸ‰ é‡å¤§æˆå°±ï¼š**
- âœ… å®Œå…¨è§£å†³äº†Docker Compose vs Kubernetesæƒé™å·®å¼‚
- âœ… å®ç°äº†ç”Ÿäº§çº§Init Containerå®‰å…¨æ¶æ„
- âœ… éªŒè¯äº†å®Œæ•´çš„8æ­¥workflowå¯è¡Œæ€§
- âœ… å»ºç«‹äº†å¯æ‰©å±•çš„Tekton GPU pipelineæ¡†æ¶

**ğŸ“‹ æŠ€æœ¯å€ºåŠ¡ï¼š**
- Notebookç‰¹å®šçš„RMMå…¼å®¹æ€§éœ€è¦åº”ç”¨å±‚é¢è§£å†³
- å¯é€šè¿‡minimal code changeæˆ–custom imageè§£å†³

**ğŸš€ ç”Ÿäº§å°±ç»ªçŠ¶æ€ï¼š**
- åŸºç¡€è®¾æ–½ï¼š100%å°±ç»ª
- å®‰å…¨æ¨¡å‹ï¼šç”Ÿäº§çº§
- å¯æ‰©å±•æ€§ï¼šå·²éªŒè¯
- ç›‘æ§èƒ½åŠ›ï¼šå®Œæ•´

æ­¤è§£å†³æ–¹æ¡ˆä¸ºGPUç§‘å­¦è®¡ç®—workloadåœ¨Kubernetesä¸Šçš„ç”Ÿäº§éƒ¨ç½²æä¾›äº†å®Œæ•´çš„ã€å®‰å…¨çš„ã€å¯æ‰©å±•çš„åŸºç¡€æ¶æ„ã€‚

## 15. RAPIDSç”¨æˆ·UIDä¿®æ­£ - é‡å¤§çªç ´ ğŸ‰

### é—®é¢˜å‘ç°
åœ¨æ‰§è¡Œ`gpu-production-init-simple-test`æ—¶ï¼Œç”¨æˆ·å‘ç°å…³é”®çº¿ç´¢ï¼š
```
Running as: ubuntu (uid=1000(ubuntu) gid=1000(ubuntu))
```
è€ŒInit containerè®¾ç½®çš„æƒé™æ˜¯ç»™ï¼š
```
rapids-user-uid:1001
rapids-user-gid:1001
```

**æ ¹æœ¬åŸå› åˆ†æ**ï¼š
- **å®¹å™¨é•œåƒå®é™…ç”¨æˆ·**ï¼š`ubuntu: UID 1000, GID 1000` | `rapids: UID 1001, GID 1001`
- **é”™è¯¯é…ç½®**ï¼š`runAsUser: 1000` (ubuntuç”¨æˆ·) 
- **æƒé™ç›®æ ‡**ï¼šInit Containerç»™UID 1001 (rapidsç”¨æˆ·) è®¾ç½®æƒé™
- **ç»“æœ**ï¼šæƒé™ä¸åŒ¹é…å¯¼è‡´Python/condaè®¿é—®å¤±è´¥

### ä¿®æ­£æ–¹æ¡ˆ
**åˆ›å»º** `examples/tasks/gpu-papermill-execution-production-rapids-fixed.yaml`ï¼š

**å…³é”®ä¿®æ­£**ï¼š
```yaml
securityContext:
  runAsUser: 1001  # CORRECTED: ä½¿ç”¨å®é™…çš„RAPIDSç”¨æˆ·UID 1001ï¼Œä¸æ˜¯1000
  runAsGroup: 1001 # CORRECTED: ä½¿ç”¨å®é™…çš„RAPIDSç»„GID 1001ï¼Œä¸æ˜¯1000
```

**Init Containerå¢å¼º**ï¼š
```bash
# è·å–å®é™…çš„RAPIDSç”¨æˆ·UID
if id rapids >/dev/null 2>&1; then
  RAPIDS_UID=$(id -u rapids)  # å®é™…ç»“æœï¼š1001
  RAPIDS_GID=$(id -g rapids)  # å®é™…ç»“æœï¼š1001
  echo "âœ… RAPIDS user found with actual UID: $(id rapids)"
```

### éªŒè¯ç»“æœ - é‡å¤§æˆåŠŸï¼

**âœ… æƒé™é—®é¢˜å½»åº•è§£å†³**ï¼š
```
Running as: rapids (uid=1001(rapids) gid=1001(rapids))
Home: /home/rapids
```

**âœ… Pythonç¯å¢ƒå®Œå…¨å¯è®¿é—®**ï¼š
- âœ… Python OK
- âœ… pip OK  
- âœ… conda OK
- âœ… ä¸å†æœ‰Permission deniedé”™è¯¯

**âœ… NotebookæˆåŠŸå¼€å§‹æ‰§è¡Œ**ï¼š
- âœ… æˆåŠŸå¯¼å…¥scanpyã€cupyã€rapids_singlecell
- âœ… Papermillæ­£å¸¸å¯åŠ¨å’Œè¿æ¥kernel
- âœ… æ‰§è¡Œåˆ°GPUç›¸å…³ä»£ç æ‰å‡ºç°æ–°çš„é—®é¢˜

**âœ… GPUåŸºç¡€è®¾æ–½éªŒè¯å®Œå…¨æ­£å¸¸**ï¼š
- âœ… GPU Operator: `nvidia-gpu-operator` namespace è¿è¡Œæ­£å¸¸
- âœ… è®¾å¤‡æ’ä»¶: `nvidia-device-plugin-daemonset` æ­£å¸¸
- âœ… èŠ‚ç‚¹èµ„æº: `nvidia.com/gpu: 4`, NVIDIA-A16, 15356MB
- âœ… èµ„æºåˆ†é…: Podæ­£ç¡®è·å¾— `nvidia.com/gpu: 1`

### æ–°é—®é¢˜è¯†åˆ«

**âŒ å®¹å™¨å†…GPUè®¾å¤‡è®¿é—®**ï¼š
- å°½ç®¡Kubernetesæ­£ç¡®åˆ†é…GPUèµ„æºï¼Œå®¹å™¨å†…æ£€æµ‹åˆ°ï¼š
- `No NVIDIA GPU detected`
- `cudaErrorNoDevice: no CUDA-capable device is detected`

**âŒ RMMå…¼å®¹æ€§**ï¼š
- `AttributeError: 'CUDARuntimeError' object has no attribute 'msg'`
- è¿™æ˜¯RMMåº“ç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜ï¼Œä¸æ˜¯æƒé™é—®é¢˜

### é‡Œç¨‹ç¢‘æ„ä¹‰

**ğŸ¯ æ ¹æœ¬é—®é¢˜è§£å†³**ï¼šDocker Compose vs Kubernetesçš„æƒé™å·®å¼‚é—®é¢˜å½»åº•è§£å†³
**ğŸ—ï¸ æ¶æ„æˆç†Ÿ**ï¼šInit Containeræ¨¡å¼çš„ç”Ÿäº§çº§å®ç°
**ğŸ” è¯Šæ–­å‡†ç¡®**ï¼šç”¨æˆ·è§‚å¯ŸåŠ›å‘ç°äº†å…³é”®çš„UIDä¸åŒ¹é…é—®é¢˜
**ğŸš€ æŠ€æœ¯çªç ´**ï¼šä»æƒé™å¤±è´¥åˆ°æˆåŠŸæ‰§è¡Œnotebookçš„é‡å¤§è¿›å±•

### ä¸‹ä¸€æ­¥

**å½“å‰ä¼˜å…ˆçº§**ï¼š
1. è¯Šæ–­å®¹å™¨å†…GPUè®¾å¤‡è®¿é—®é—®é¢˜ï¼ˆç¡¬ä»¶æ˜ å°„å±‚é¢ï¼‰
2. è§£å†³RMMå…¼å®¹æ€§é—®é¢˜ï¼ˆå¯èƒ½éœ€è¦ç®€åŒ–æµ‹è¯•æˆ–ç‰ˆæœ¬è°ƒæ•´ï¼‰
3. å®Œæˆå®Œæ•´çš„8æ­¥workflowéªŒè¯

**æŠ€æœ¯å€ºåŠ¡**ï¼š
- GPUè®¾å¤‡æ’ä»¶æ˜ å°„æœºåˆ¶éœ€è¦è¿›ä¸€æ­¥è°ƒè¯•
- RMMåˆå§‹åŒ–éœ€è¦é”™è¯¯å¤„ç†æˆ–ç‰ˆæœ¬å…¼å®¹æ€§ä¿®å¤

è¿™æ¬¡çªç ´ä¸ºæ•´ä¸ªé¡¹ç›®å¥ å®šäº†åšå®çš„åŸºç¡€ï¼Œæƒé™é—®é¢˜çš„å½»åº•è§£å†³ä¸ºåç»­å·¥ä½œæ‰«æ¸…äº†æœ€å¤§çš„éšœç¢ã€‚ 